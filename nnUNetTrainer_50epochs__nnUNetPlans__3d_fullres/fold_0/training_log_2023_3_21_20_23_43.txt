
This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'num_pool_per_axis': [3, 3, 3], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2023-03-21 20:23:48.375206: unpacking dataset... 
2023-03-21 20:23:51.238022: unpacking done... 
2023-03-21 20:23:51.239937: do_dummy_2d_data_aug: False 
2023-03-21 20:23:51.244228: Using splits from existing split file: /data_hdd/users/zengzhilin/nnUNet_preprocessed/Dataset004_Hippocampus/splits_final.json 
2023-03-21 20:23:51.244968: The split file contains 5 splits. 
2023-03-21 20:23:51.245114: Desired fold for training: 0 
2023-03-21 20:23:51.245231: This split has 208 training and 52 validation cases. 
2023-03-21 20:23:51.308522: Unable to plot network architecture: 
2023-03-21 20:23:51.308711: No module named 'hiddenlayer' 
2023-03-21 20:23:51.357350:  
2023-03-21 20:23:51.357583: Epoch 0 
2023-03-21 20:23:51.357936: Current learning rate: 0.01 
2023-03-21 20:24:10.388566: train_loss -0.2464 
2023-03-21 20:24:10.388956: val_loss -0.5226 
2023-03-21 20:24:10.389075: Pseudo dice [0.3181, 0.6331] 
2023-03-21 20:24:10.389417: Epoch time: 19.03 s 
2023-03-21 20:24:10.389791: Yayy! New best EMA pseudo Dice: 0.4756 
2023-03-21 20:24:11.783244:  
2023-03-21 20:24:11.783718: Epoch 1 
2023-03-21 20:24:11.784069: Current learning rate: 0.00982 
2023-03-21 20:24:25.930831: train_loss -0.6863 
2023-03-21 20:24:25.931143: val_loss -0.7918 
2023-03-21 20:24:25.931267: Pseudo dice [0.8609, 0.8388] 
2023-03-21 20:24:25.931386: Epoch time: 14.15 s 
2023-03-21 20:24:25.931483: Yayy! New best EMA pseudo Dice: 0.513 
2023-03-21 20:24:28.825561:  
2023-03-21 20:24:28.825806: Epoch 2 
2023-03-21 20:24:28.826034: Current learning rate: 0.00964 
2023-03-21 20:24:44.740795: train_loss -0.7873 
2023-03-21 20:24:44.741168: val_loss -0.8086 
2023-03-21 20:24:44.741325: Pseudo dice [0.868, 0.854] 
2023-03-21 20:24:44.741488: Epoch time: 15.92 s 
2023-03-21 20:24:44.741623: Yayy! New best EMA pseudo Dice: 0.5478 
2023-03-21 20:24:47.041970:  
2023-03-21 20:24:47.043024: Epoch 3 
2023-03-21 20:24:47.043510: Current learning rate: 0.00946 
2023-03-21 20:25:03.043024: train_loss -0.8059 
2023-03-21 20:25:03.043412: val_loss -0.8191 
2023-03-21 20:25:03.043577: Pseudo dice [0.8762, 0.8602] 
2023-03-21 20:25:03.043761: Epoch time: 16.0 s 
2023-03-21 20:25:03.043910: Yayy! New best EMA pseudo Dice: 0.5799 
2023-03-21 20:25:05.092431:  
2023-03-21 20:25:05.092683: Epoch 4 
2023-03-21 20:25:05.092901: Current learning rate: 0.00928 
2023-03-21 20:25:20.670883: train_loss -0.8159 
2023-03-21 20:25:20.671358: val_loss -0.8255 
2023-03-21 20:25:20.671578: Pseudo dice [0.8825, 0.8629] 
2023-03-21 20:25:20.671795: Epoch time: 15.58 s 
2023-03-21 20:25:20.671992: Yayy! New best EMA pseudo Dice: 0.6092 
2023-03-21 20:25:22.651113:  
2023-03-21 20:25:22.651344: Epoch 5 
2023-03-21 20:25:22.651527: Current learning rate: 0.0091 
2023-03-21 20:25:38.057510: train_loss -0.8214 
2023-03-21 20:25:38.057820: val_loss -0.828 
2023-03-21 20:25:38.057943: Pseudo dice [0.885, 0.8615] 
2023-03-21 20:25:38.058064: Epoch time: 15.41 s 
2023-03-21 20:25:38.058170: Yayy! New best EMA pseudo Dice: 0.6356 
2023-03-21 20:25:40.004565:  
2023-03-21 20:25:40.004735: Epoch 6 
2023-03-21 20:25:40.004870: Current learning rate: 0.00891 
2023-03-21 20:25:55.570019: train_loss -0.8271 
2023-03-21 20:25:55.570376: val_loss -0.8298 
2023-03-21 20:25:55.570507: Pseudo dice [0.8854, 0.865] 
2023-03-21 20:25:55.570634: Epoch time: 15.57 s 
2023-03-21 20:25:55.570766: Yayy! New best EMA pseudo Dice: 0.6595 
2023-03-21 20:25:57.695711:  
2023-03-21 20:25:57.695895: Epoch 7 
2023-03-21 20:25:57.696028: Current learning rate: 0.00873 
2023-03-21 20:26:13.282694: train_loss -0.8309 
2023-03-21 20:26:13.283281: val_loss -0.8254 
2023-03-21 20:26:13.283779: Pseudo dice [0.8838, 0.8612] 
2023-03-21 20:26:13.283982: Epoch time: 15.59 s 
2023-03-21 20:26:13.284216: Yayy! New best EMA pseudo Dice: 0.6808 
2023-03-21 20:26:15.244158:  
2023-03-21 20:26:15.244361: Epoch 8 
2023-03-21 20:26:15.244526: Current learning rate: 0.00855 
2023-03-21 20:26:30.551012: train_loss -0.8347 
2023-03-21 20:26:30.551392: val_loss -0.8315 
2023-03-21 20:26:30.551511: Pseudo dice [0.8838, 0.8677] 
2023-03-21 20:26:30.551633: Epoch time: 15.31 s 
2023-03-21 20:26:30.551735: Yayy! New best EMA pseudo Dice: 0.7003 
2023-03-21 20:26:32.585893:  
2023-03-21 20:26:32.586151: Epoch 9 
2023-03-21 20:26:32.586391: Current learning rate: 0.00836 
2023-03-21 20:26:47.869372: train_loss -0.837 
2023-03-21 20:26:47.869725: val_loss -0.8344 
2023-03-21 20:26:47.869843: Pseudo dice [0.8877, 0.8686] 
2023-03-21 20:26:47.869968: Epoch time: 15.28 s 
2023-03-21 20:26:47.870064: Yayy! New best EMA pseudo Dice: 0.7181 
2023-03-21 20:26:49.695946:  
2023-03-21 20:26:49.696128: Epoch 10 
2023-03-21 20:26:49.696248: Current learning rate: 0.00818 
2023-03-21 20:27:04.945415: train_loss -0.8375 
2023-03-21 20:27:04.945795: val_loss -0.8334 
2023-03-21 20:27:04.945933: Pseudo dice [0.8876, 0.8678] 
2023-03-21 20:27:04.946070: Epoch time: 15.25 s 
2023-03-21 20:27:04.946177: Yayy! New best EMA pseudo Dice: 0.7341 
2023-03-21 20:27:06.929554:  
2023-03-21 20:27:06.929699: Epoch 11 
2023-03-21 20:27:06.929845: Current learning rate: 0.008 
2023-03-21 20:27:22.536312: train_loss -0.841 
2023-03-21 20:27:22.536777: val_loss -0.8382 
2023-03-21 20:27:22.536986: Pseudo dice [0.8933, 0.8686] 
2023-03-21 20:27:22.537154: Epoch time: 15.61 s 
2023-03-21 20:27:22.537287: Yayy! New best EMA pseudo Dice: 0.7487 
2023-03-21 20:27:24.757452:  
2023-03-21 20:27:24.757723: Epoch 12 
2023-03-21 20:27:24.757953: Current learning rate: 0.00781 
2023-03-21 20:27:40.231630: train_loss -0.8434 
2023-03-21 20:27:40.231947: val_loss -0.8398 
2023-03-21 20:27:40.232118: Pseudo dice [0.892, 0.8722] 
2023-03-21 20:27:40.232299: Epoch time: 15.48 s 
2023-03-21 20:27:40.232466: Yayy! New best EMA pseudo Dice: 0.7621 
2023-03-21 20:27:42.291835:  
2023-03-21 20:27:42.292069: Epoch 13 
2023-03-21 20:27:42.292308: Current learning rate: 0.00763 
2023-03-21 20:27:57.518958: train_loss -0.844 
2023-03-21 20:27:57.519244: val_loss -0.842 
2023-03-21 20:27:57.519357: Pseudo dice [0.8933, 0.8739] 
2023-03-21 20:27:57.519468: Epoch time: 15.23 s 
2023-03-21 20:27:57.519559: Yayy! New best EMA pseudo Dice: 0.7742 
2023-03-21 20:27:59.520831:  
2023-03-21 20:27:59.520985: Epoch 14 
2023-03-21 20:27:59.521110: Current learning rate: 0.00744 
2023-03-21 20:28:15.183587: train_loss -0.8479 
2023-03-21 20:28:15.184028: val_loss -0.8345 
2023-03-21 20:28:15.184215: Pseudo dice [0.888, 0.8675] 
2023-03-21 20:28:15.184420: Epoch time: 15.66 s 
2023-03-21 20:28:15.184664: Yayy! New best EMA pseudo Dice: 0.7846 
2023-03-21 20:28:17.371373:  
2023-03-21 20:28:17.371517: Epoch 15 
2023-03-21 20:28:17.371636: Current learning rate: 0.00725 
2023-03-21 20:28:32.694953: train_loss -0.8477 
2023-03-21 20:28:32.695279: val_loss -0.8405 
2023-03-21 20:28:32.695404: Pseudo dice [0.8928, 0.8714] 
2023-03-21 20:28:32.695531: Epoch time: 15.32 s 
2023-03-21 20:28:32.695637: Yayy! New best EMA pseudo Dice: 0.7943 
2023-03-21 20:28:34.600630:  
2023-03-21 20:28:34.600916: Epoch 16 
2023-03-21 20:28:34.601089: Current learning rate: 0.00707 
2023-03-21 20:28:50.007595: train_loss -0.8511 
2023-03-21 20:28:50.007992: val_loss -0.8466 
2023-03-21 20:28:50.008194: Pseudo dice [0.8966, 0.8784] 
2023-03-21 20:28:50.008369: Epoch time: 15.41 s 
2023-03-21 20:28:50.008518: Yayy! New best EMA pseudo Dice: 0.8037 
2023-03-21 20:28:52.283208:  
2023-03-21 20:28:52.283369: Epoch 17 
2023-03-21 20:28:52.283498: Current learning rate: 0.00688 
2023-03-21 20:29:07.650043: train_loss -0.8516 
2023-03-21 20:29:07.650581: val_loss -0.8415 
2023-03-21 20:29:07.651365: Pseudo dice [0.8922, 0.8732] 
2023-03-21 20:29:07.651679: Epoch time: 15.37 s 
2023-03-21 20:29:07.651936: Yayy! New best EMA pseudo Dice: 0.8116 
2023-03-21 20:29:09.549658:  
2023-03-21 20:29:09.549959: Epoch 18 
2023-03-21 20:29:09.550083: Current learning rate: 0.00669 
2023-03-21 20:29:24.986291: train_loss -0.8525 
2023-03-21 20:29:24.986715: val_loss -0.8441 
2023-03-21 20:29:24.986935: Pseudo dice [0.8955, 0.8735] 
2023-03-21 20:29:24.987127: Epoch time: 15.44 s 
2023-03-21 20:29:24.987526: Yayy! New best EMA pseudo Dice: 0.8189 
2023-03-21 20:29:27.010433:  
2023-03-21 20:29:27.010643: Epoch 19 
2023-03-21 20:29:27.010813: Current learning rate: 0.0065 
2023-03-21 20:29:42.355966: train_loss -0.8558 
2023-03-21 20:29:42.356717: val_loss -0.8415 
2023-03-21 20:29:42.356972: Pseudo dice [0.8927, 0.8741] 
2023-03-21 20:29:42.357297: Epoch time: 15.35 s 
2023-03-21 20:29:42.357676: Yayy! New best EMA pseudo Dice: 0.8253 
2023-03-21 20:29:44.586415:  
2023-03-21 20:29:44.586624: Epoch 20 
2023-03-21 20:29:44.586778: Current learning rate: 0.00631 
2023-03-21 20:29:59.932585: train_loss -0.8525 
2023-03-21 20:29:59.932908: val_loss -0.8464 
2023-03-21 20:29:59.933042: Pseudo dice [0.8956, 0.8765] 
2023-03-21 20:29:59.933174: Epoch time: 15.35 s 
2023-03-21 20:29:59.933285: Yayy! New best EMA pseudo Dice: 0.8314 
2023-03-21 20:30:02.051167:  
2023-03-21 20:30:02.051373: Epoch 21 
2023-03-21 20:30:02.051499: Current learning rate: 0.00612 
2023-03-21 20:30:17.293458: train_loss -0.856 
2023-03-21 20:30:17.293890: val_loss -0.8421 
2023-03-21 20:30:17.294066: Pseudo dice [0.8926, 0.8737] 
2023-03-21 20:30:17.294237: Epoch time: 15.24 s 
2023-03-21 20:30:17.294374: Yayy! New best EMA pseudo Dice: 0.8366 
2023-03-21 20:30:19.292256:  
2023-03-21 20:30:19.292433: Epoch 22 
2023-03-21 20:30:19.292557: Current learning rate: 0.00593 
2023-03-21 20:30:34.624138: train_loss -0.8587 
2023-03-21 20:30:34.624469: val_loss -0.8413 
2023-03-21 20:30:34.624599: Pseudo dice [0.891, 0.8752] 
2023-03-21 20:30:34.624716: Epoch time: 15.33 s 
2023-03-21 20:30:34.624812: Yayy! New best EMA pseudo Dice: 0.8412 
2023-03-21 20:30:36.584678:  
2023-03-21 20:30:36.584857: Epoch 23 
2023-03-21 20:30:36.584997: Current learning rate: 0.00574 
2023-03-21 20:30:52.015193: train_loss -0.8586 
2023-03-21 20:30:52.016032: val_loss -0.843 
2023-03-21 20:30:52.016288: Pseudo dice [0.8968, 0.8706] 
2023-03-21 20:30:52.016620: Epoch time: 15.43 s 
2023-03-21 20:30:52.016826: Yayy! New best EMA pseudo Dice: 0.8455 
2023-03-21 20:30:53.946581:  
2023-03-21 20:30:53.946759: Epoch 24 
2023-03-21 20:30:53.946924: Current learning rate: 0.00555 
2023-03-21 20:31:09.293487: train_loss -0.8595 
2023-03-21 20:31:09.293776: val_loss -0.8469 
2023-03-21 20:31:09.293900: Pseudo dice [0.8971, 0.8768] 
2023-03-21 20:31:09.294020: Epoch time: 15.35 s 
2023-03-21 20:31:09.294132: Yayy! New best EMA pseudo Dice: 0.8496 
2023-03-21 20:31:11.132383:  
2023-03-21 20:31:11.132536: Epoch 25 
2023-03-21 20:31:11.132656: Current learning rate: 0.00536 
2023-03-21 20:31:26.544008: train_loss -0.8596 
2023-03-21 20:31:26.544328: val_loss -0.8496 
2023-03-21 20:31:26.544445: Pseudo dice [0.8987, 0.8787] 
2023-03-21 20:31:26.544561: Epoch time: 15.41 s 
2023-03-21 20:31:26.544665: Yayy! New best EMA pseudo Dice: 0.8535 
2023-03-21 20:31:28.427560:  
2023-03-21 20:31:28.427752: Epoch 26 
2023-03-21 20:31:28.427888: Current learning rate: 0.00517 
2023-03-21 20:31:43.838836: train_loss -0.8624 
2023-03-21 20:31:43.839286: val_loss -0.8477 
2023-03-21 20:31:43.839460: Pseudo dice [0.8976, 0.8763] 
2023-03-21 20:31:43.839622: Epoch time: 15.41 s 
2023-03-21 20:31:43.839752: Yayy! New best EMA pseudo Dice: 0.8569 
2023-03-21 20:31:46.046462:  
2023-03-21 20:31:46.046633: Epoch 27 
2023-03-21 20:31:46.046770: Current learning rate: 0.00497 
2023-03-21 20:32:01.404014: train_loss -0.8623 
2023-03-21 20:32:01.404354: val_loss -0.8489 
2023-03-21 20:32:01.404475: Pseudo dice [0.8985, 0.8791] 
2023-03-21 20:32:01.404593: Epoch time: 15.36 s 
2023-03-21 20:32:01.404689: Yayy! New best EMA pseudo Dice: 0.8601 
2023-03-21 20:32:03.282880:  
2023-03-21 20:32:03.283070: Epoch 28 
2023-03-21 20:32:03.283214: Current learning rate: 0.00478 
2023-03-21 20:32:18.847952: train_loss -0.8654 
2023-03-21 20:32:18.848428: val_loss -0.8478 
2023-03-21 20:32:18.848840: Pseudo dice [0.8966, 0.8791] 
2023-03-21 20:32:18.849067: Epoch time: 15.57 s 
2023-03-21 20:32:18.849315: Yayy! New best EMA pseudo Dice: 0.8628 
2023-03-21 20:32:20.846100:  
2023-03-21 20:32:20.846562: Epoch 29 
2023-03-21 20:32:20.847015: Current learning rate: 0.00458 
2023-03-21 20:32:36.490389: train_loss -0.8651 
2023-03-21 20:32:36.490693: val_loss -0.8488 
2023-03-21 20:32:36.490835: Pseudo dice [0.8987, 0.8786] 
2023-03-21 20:32:36.490951: Epoch time: 15.65 s 
2023-03-21 20:32:36.491050: Yayy! New best EMA pseudo Dice: 0.8654 
2023-03-21 20:32:38.552209:  
2023-03-21 20:32:38.552395: Epoch 30 
2023-03-21 20:32:38.552539: Current learning rate: 0.00438 
2023-03-21 20:32:54.286535: train_loss -0.8651 
2023-03-21 20:32:54.287095: val_loss -0.8446 
2023-03-21 20:32:54.287306: Pseudo dice [0.8951, 0.8759] 
2023-03-21 20:32:54.287500: Epoch time: 15.74 s 
2023-03-21 20:32:54.287658: Yayy! New best EMA pseudo Dice: 0.8674 
2023-03-21 20:32:56.203047:  
2023-03-21 20:32:56.203217: Epoch 31 
2023-03-21 20:32:56.203361: Current learning rate: 0.00419 
2023-03-21 20:33:11.827137: train_loss -0.8657 
2023-03-21 20:33:11.827545: val_loss -0.85 
2023-03-21 20:33:11.827704: Pseudo dice [0.9, 0.8784] 
2023-03-21 20:33:11.827830: Epoch time: 15.63 s 
2023-03-21 20:33:11.827945: Yayy! New best EMA pseudo Dice: 0.8696 
2023-03-21 20:33:13.672736:  
2023-03-21 20:33:13.673058: Epoch 32 
2023-03-21 20:33:13.673206: Current learning rate: 0.00399 
2023-03-21 20:33:29.495869: train_loss -0.8652 
2023-03-21 20:33:29.496609: val_loss -0.8507 
2023-03-21 20:33:29.497410: Pseudo dice [0.9001, 0.8809] 
2023-03-21 20:33:29.497850: Epoch time: 15.82 s 
2023-03-21 20:33:29.498210: Yayy! New best EMA pseudo Dice: 0.8717 
2023-03-21 20:33:31.583755:  
2023-03-21 20:33:31.584057: Epoch 33 
2023-03-21 20:33:31.584220: Current learning rate: 0.00379 
2023-03-21 20:33:47.320834: train_loss -0.8671 
2023-03-21 20:33:47.321243: val_loss -0.8452 
2023-03-21 20:33:47.321522: Pseudo dice [0.8969, 0.8736] 
2023-03-21 20:33:47.321773: Epoch time: 15.74 s 
2023-03-21 20:33:47.322063: Yayy! New best EMA pseudo Dice: 0.873 
2023-03-21 20:33:49.554254:  
2023-03-21 20:33:49.555022: Epoch 34 
2023-03-21 20:33:49.555567: Current learning rate: 0.00359 
2023-03-21 20:34:05.233639: train_loss -0.8679 
2023-03-21 20:34:05.233987: val_loss -0.849 
2023-03-21 20:34:05.234115: Pseudo dice [0.8986, 0.8787] 
2023-03-21 20:34:05.234676: Epoch time: 15.68 s 
2023-03-21 20:34:05.234842: Yayy! New best EMA pseudo Dice: 0.8746 
2023-03-21 20:34:07.220948:  
2023-03-21 20:34:07.221176: Epoch 35 
2023-03-21 20:34:07.221322: Current learning rate: 0.00338 
2023-03-21 20:34:22.995200: train_loss -0.869 
2023-03-21 20:34:22.995607: val_loss -0.8493 
2023-03-21 20:34:22.995807: Pseudo dice [0.8996, 0.8794] 
2023-03-21 20:34:22.995944: Epoch time: 15.78 s 
2023-03-21 20:34:22.996058: Yayy! New best EMA pseudo Dice: 0.8761 
2023-03-21 20:34:24.905162:  
2023-03-21 20:34:24.905500: Epoch 36 
2023-03-21 20:34:24.905734: Current learning rate: 0.00318 
2023-03-21 20:34:40.683902: train_loss -0.8703 
2023-03-21 20:34:40.684577: val_loss -0.8491 
2023-03-21 20:34:40.684881: Pseudo dice [0.9009, 0.8785] 
2023-03-21 20:34:40.685112: Epoch time: 15.78 s 
2023-03-21 20:34:40.685319: Yayy! New best EMA pseudo Dice: 0.8775 
2023-03-21 20:34:43.046653:  
2023-03-21 20:34:43.046882: Epoch 37 
2023-03-21 20:34:43.047026: Current learning rate: 0.00297 
2023-03-21 20:34:58.786416: train_loss -0.8705 
2023-03-21 20:34:58.786948: val_loss -0.8545 
2023-03-21 20:34:58.787179: Pseudo dice [0.9024, 0.8835] 
2023-03-21 20:34:58.787671: Epoch time: 15.74 s 
2023-03-21 20:34:58.787804: Yayy! New best EMA pseudo Dice: 0.879 
2023-03-21 20:35:00.696222:  
2023-03-21 20:35:00.696421: Epoch 38 
2023-03-21 20:35:00.696553: Current learning rate: 0.00277 
2023-03-21 20:35:16.311803: train_loss -0.8714 
2023-03-21 20:35:16.312209: val_loss -0.848 
2023-03-21 20:35:16.312375: Pseudo dice [0.8972, 0.8776] 
2023-03-21 20:35:16.312547: Epoch time: 15.62 s 
2023-03-21 20:35:16.312678: Yayy! New best EMA pseudo Dice: 0.8798 
2023-03-21 20:35:18.388939:  
2023-03-21 20:35:18.389098: Epoch 39 
2023-03-21 20:35:18.389232: Current learning rate: 0.00256 
2023-03-21 20:35:34.128343: train_loss -0.8722 
2023-03-21 20:35:34.128748: val_loss -0.8525 
2023-03-21 20:35:34.129048: Pseudo dice [0.9017, 0.8813] 
2023-03-21 20:35:34.129367: Epoch time: 15.74 s 
2023-03-21 20:35:34.129654: Yayy! New best EMA pseudo Dice: 0.881 
2023-03-21 20:35:35.989789:  
2023-03-21 20:35:35.989981: Epoch 40 
2023-03-21 20:35:35.990119: Current learning rate: 0.00235 
2023-03-21 20:35:51.724798: train_loss -0.8747 
2023-03-21 20:35:51.725133: val_loss -0.8508 
2023-03-21 20:35:51.725255: Pseudo dice [0.8991, 0.8817] 
2023-03-21 20:35:51.725372: Epoch time: 15.74 s 
2023-03-21 20:35:51.725469: Yayy! New best EMA pseudo Dice: 0.882 
2023-03-21 20:35:53.736461:  
2023-03-21 20:35:53.737059: Epoch 41 
2023-03-21 20:35:53.737881: Current learning rate: 0.00214 
2023-03-21 20:36:09.533135: train_loss -0.8738 
2023-03-21 20:36:09.533440: val_loss -0.8503 
2023-03-21 20:36:09.533566: Pseudo dice [0.9016, 0.8797] 
2023-03-21 20:36:09.533682: Epoch time: 15.8 s 
2023-03-21 20:36:09.533783: Yayy! New best EMA pseudo Dice: 0.8828 
2023-03-21 20:36:11.815358:  
2023-03-21 20:36:11.815563: Epoch 42 
2023-03-21 20:36:11.815704: Current learning rate: 0.00192 
2023-03-21 20:36:27.568819: train_loss -0.8753 
2023-03-21 20:36:27.569190: val_loss -0.8514 
2023-03-21 20:36:27.569346: Pseudo dice [0.8995, 0.8808] 
2023-03-21 20:36:27.569499: Epoch time: 15.75 s 
2023-03-21 20:36:27.569624: Yayy! New best EMA pseudo Dice: 0.8836 
2023-03-21 20:36:29.463693:  
2023-03-21 20:36:29.464153: Epoch 43 
2023-03-21 20:36:29.464387: Current learning rate: 0.0017 
2023-03-21 20:36:45.469564: train_loss -0.8737 
2023-03-21 20:36:45.469891: val_loss -0.8503 
2023-03-21 20:36:45.470015: Pseudo dice [0.8982, 0.8805] 
2023-03-21 20:36:45.470134: Epoch time: 16.01 s 
2023-03-21 20:36:45.470239: Yayy! New best EMA pseudo Dice: 0.8841 
2023-03-21 20:36:47.339201:  
2023-03-21 20:36:47.339370: Epoch 44 
2023-03-21 20:36:47.339505: Current learning rate: 0.00148 
2023-03-21 20:37:02.971769: train_loss -0.8755 
2023-03-21 20:37:02.972209: val_loss -0.8542 
2023-03-21 20:37:02.972374: Pseudo dice [0.9029, 0.8818] 
2023-03-21 20:37:02.972532: Epoch time: 15.63 s 
2023-03-21 20:37:02.972661: Yayy! New best EMA pseudo Dice: 0.885 
2023-03-21 20:37:04.920144:  
2023-03-21 20:37:04.920429: Epoch 45 
2023-03-21 20:37:04.920747: Current learning rate: 0.00126 
2023-03-21 20:37:20.783211: train_loss -0.876 
2023-03-21 20:37:20.783529: val_loss -0.8458 
2023-03-21 20:37:20.783652: Pseudo dice [0.8976, 0.8768] 
2023-03-21 20:37:20.784002: Epoch time: 15.86 s 
2023-03-21 20:37:20.784234: Yayy! New best EMA pseudo Dice: 0.8852 
2023-03-21 20:37:22.632159:  
2023-03-21 20:37:22.632383: Epoch 46 
2023-03-21 20:37:22.632537: Current learning rate: 0.00103 
2023-03-21 20:37:38.430470: train_loss -0.8778 
2023-03-21 20:37:38.430921: val_loss -0.8496 
2023-03-21 20:37:38.431085: Pseudo dice [0.9001, 0.8792] 
2023-03-21 20:37:38.431263: Epoch time: 15.8 s 
2023-03-21 20:37:38.431396: Yayy! New best EMA pseudo Dice: 0.8856 
2023-03-21 20:37:40.489963:  
2023-03-21 20:37:40.490139: Epoch 47 
2023-03-21 20:37:40.490273: Current learning rate: 0.00079 
2023-03-21 20:37:56.490264: train_loss -0.8793 
2023-03-21 20:37:56.490568: val_loss -0.8456 
2023-03-21 20:37:56.490688: Pseudo dice [0.8964, 0.8776] 
2023-03-21 20:37:56.490842: Epoch time: 16.0 s 
2023-03-21 20:37:56.490943: Yayy! New best EMA pseudo Dice: 0.8858 
2023-03-21 20:37:58.296077:  
2023-03-21 20:37:58.296282: Epoch 48 
2023-03-21 20:37:58.296417: Current learning rate: 0.00055 
2023-03-21 20:38:13.953094: train_loss -0.8777 
2023-03-21 20:38:13.953390: val_loss -0.8512 
2023-03-21 20:38:13.953520: Pseudo dice [0.8996, 0.8809] 
2023-03-21 20:38:13.953637: Epoch time: 15.66 s 
2023-03-21 20:38:13.953731: Yayy! New best EMA pseudo Dice: 0.8862 
2023-03-21 20:38:15.932261:  
2023-03-21 20:38:15.932554: Epoch 49 
2023-03-21 20:38:15.932731: Current learning rate: 0.0003 
2023-03-21 20:38:31.811961: train_loss -0.8787 
2023-03-21 20:38:31.812268: val_loss -0.8456 
2023-03-21 20:38:31.812398: Pseudo dice [0.8969, 0.8774] 
2023-03-21 20:38:31.812527: Epoch time: 15.88 s 
2023-03-21 20:38:31.812648: Yayy! New best EMA pseudo Dice: 0.8863 
2023-03-21 20:38:34.248313: Using splits from existing split file: /data_hdd/users/zengzhilin/nnUNet_preprocessed/Dataset004_Hippocampus/splits_final.json 
2023-03-21 20:38:34.249882: The split file contains 5 splits. 
2023-03-21 20:38:34.250014: Desired fold for training: 0 
2023-03-21 20:38:34.250096: This split has 208 training and 52 validation cases. 
2023-03-21 20:38:34.250821: predicting hippocampus_017 
2023-03-21 20:38:34.473006: predicting hippocampus_019 
2023-03-21 20:38:34.618654: predicting hippocampus_033 
2023-03-21 20:38:34.700503: predicting hippocampus_035 
2023-03-21 20:38:34.780936: predicting hippocampus_037 
2023-03-21 20:38:34.863818: predicting hippocampus_049 
2023-03-21 20:38:34.988702: predicting hippocampus_052 
2023-03-21 20:38:35.070682: predicting hippocampus_065 
2023-03-21 20:38:35.164145: predicting hippocampus_083 
2023-03-21 20:38:35.309418: predicting hippocampus_088 
2023-03-21 20:38:35.425638: predicting hippocampus_090 
2023-03-21 20:38:35.583996: predicting hippocampus_092 
2023-03-21 20:38:35.687547: predicting hippocampus_095 
2023-03-21 20:38:35.768361: predicting hippocampus_107 
2023-03-21 20:38:35.850215: predicting hippocampus_108 
2023-03-21 20:38:35.929718: predicting hippocampus_123 
2023-03-21 20:38:36.013474: predicting hippocampus_125 
2023-03-21 20:38:38.141344: predicting hippocampus_157 
2023-03-21 20:38:38.221344: predicting hippocampus_164 
2023-03-21 20:38:38.484719: predicting hippocampus_169 
2023-03-21 20:38:38.564932: predicting hippocampus_175 
2023-03-21 20:38:38.639664: predicting hippocampus_185 
2023-03-21 20:38:38.696978: predicting hippocampus_190 
2023-03-21 20:38:38.754076: predicting hippocampus_194 
2023-03-21 20:38:38.811021: predicting hippocampus_204 
2023-03-21 20:38:38.868125: predicting hippocampus_205 
2023-03-21 20:38:38.926596: predicting hippocampus_210 
2023-03-21 20:38:38.982399: predicting hippocampus_217 
2023-03-21 20:38:39.037616: predicting hippocampus_219 
2023-03-21 20:38:39.091878: predicting hippocampus_229 
2023-03-21 20:38:39.153280: predicting hippocampus_244 
2023-03-21 20:38:39.211900: predicting hippocampus_261 
2023-03-21 20:38:39.328227: predicting hippocampus_264 
2023-03-21 20:38:39.415457: predicting hippocampus_277 
2023-03-21 20:38:39.538248: predicting hippocampus_280 
2023-03-21 20:38:39.599933: predicting hippocampus_286 
2023-03-21 20:38:39.707207: predicting hippocampus_288 
2023-03-21 20:38:39.812889: predicting hippocampus_289 
2023-03-21 20:38:39.873919: predicting hippocampus_296 
2023-03-21 20:38:39.935074: predicting hippocampus_305 
2023-03-21 20:38:39.997701: predicting hippocampus_308 
2023-03-21 20:38:40.056195: predicting hippocampus_317 
2023-03-21 20:38:40.113287: predicting hippocampus_327 
2023-03-21 20:38:40.174446: predicting hippocampus_330 
2023-03-21 20:38:40.236354: predicting hippocampus_332 
2023-03-21 20:38:40.296964: predicting hippocampus_338 
2023-03-21 20:38:40.404765: predicting hippocampus_349 
2023-03-21 20:38:40.462995: predicting hippocampus_350 
2023-03-21 20:38:40.520561: predicting hippocampus_356 
2023-03-21 20:38:40.581151: predicting hippocampus_358 
2023-03-21 20:38:40.638158: predicting hippocampus_374 
2023-03-21 20:38:40.703761: predicting hippocampus_394 
2023-03-21 20:38:45.343271: Validation complete 
2023-03-21 20:38:45.343440: Mean Validation Dice:  0.8920046426174826 
