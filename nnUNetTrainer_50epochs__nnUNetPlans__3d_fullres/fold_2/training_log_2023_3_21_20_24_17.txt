
This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'num_pool_per_axis': [3, 3, 3], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2023-03-21 20:24:22.516421: unpacking dataset... 
2023-03-21 20:24:26.279783: unpacking done... 
2023-03-21 20:24:26.282216: do_dummy_2d_data_aug: False 
2023-03-21 20:24:26.285445: Using splits from existing split file: /data_hdd/users/zengzhilin/nnUNet_preprocessed/Dataset004_Hippocampus/splits_final.json 
2023-03-21 20:24:26.285903: The split file contains 5 splits. 
2023-03-21 20:24:26.285991: Desired fold for training: 2 
2023-03-21 20:24:26.286059: This split has 208 training and 52 validation cases. 
2023-03-21 20:24:26.390647: Unable to plot network architecture: 
2023-03-21 20:24:26.390921: No module named 'hiddenlayer' 
2023-03-21 20:24:26.484081:  
2023-03-21 20:24:26.484243: Epoch 0 
2023-03-21 20:24:26.484487: Current learning rate: 0.01 
2023-03-21 20:24:48.065768: train_loss -0.1286 
2023-03-21 20:24:48.066098: val_loss -0.4958 
2023-03-21 20:24:48.066226: Pseudo dice [0.5171, 0.0] 
2023-03-21 20:24:48.066352: Epoch time: 21.58 s 
2023-03-21 20:24:48.066456: Yayy! New best EMA pseudo Dice: 0.2585 
2023-03-21 20:24:49.736515:  
2023-03-21 20:24:49.736733: Epoch 1 
2023-03-21 20:24:49.736883: Current learning rate: 0.00982 
2023-03-21 20:25:05.503690: train_loss -0.6819 
2023-03-21 20:25:05.504248: val_loss -0.7867 
2023-03-21 20:25:05.504394: Pseudo dice [0.8579, 0.8325] 
2023-03-21 20:25:05.504569: Epoch time: 15.77 s 
2023-03-21 20:25:05.504740: Yayy! New best EMA pseudo Dice: 0.3172 
2023-03-21 20:25:07.301210:  
2023-03-21 20:25:07.301432: Epoch 2 
2023-03-21 20:25:07.301586: Current learning rate: 0.00964 
2023-03-21 20:25:22.664026: train_loss -0.7853 
2023-03-21 20:25:22.665425: val_loss -0.8085 
2023-03-21 20:25:22.665548: Pseudo dice [0.8686, 0.8485] 
2023-03-21 20:25:22.665674: Epoch time: 15.36 s 
2023-03-21 20:25:22.665772: Yayy! New best EMA pseudo Dice: 0.3713 
2023-03-21 20:25:24.945105:  
2023-03-21 20:25:24.945359: Epoch 3 
2023-03-21 20:25:24.945719: Current learning rate: 0.00946 
2023-03-21 20:25:40.771808: train_loss -0.8032 
2023-03-21 20:25:40.772137: val_loss -0.8242 
2023-03-21 20:25:40.772254: Pseudo dice [0.8768, 0.8593] 
2023-03-21 20:25:40.772373: Epoch time: 15.83 s 
2023-03-21 20:25:40.772470: Yayy! New best EMA pseudo Dice: 0.421 
2023-03-21 20:25:42.665533:  
2023-03-21 20:25:42.665823: Epoch 4 
2023-03-21 20:25:42.666041: Current learning rate: 0.00928 
2023-03-21 20:25:57.964610: train_loss -0.8166 
2023-03-21 20:25:57.965017: val_loss -0.8262 
2023-03-21 20:25:57.965158: Pseudo dice [0.8814, 0.8597] 
2023-03-21 20:25:57.965291: Epoch time: 15.3 s 
2023-03-21 20:25:57.965398: Yayy! New best EMA pseudo Dice: 0.466 
2023-03-21 20:25:59.856571:  
2023-03-21 20:25:59.856741: Epoch 5 
2023-03-21 20:25:59.856885: Current learning rate: 0.0091 
2023-03-21 20:26:15.336240: train_loss -0.8209 
2023-03-21 20:26:15.336550: val_loss -0.829 
2023-03-21 20:26:15.336671: Pseudo dice [0.8823, 0.8626] 
2023-03-21 20:26:15.336781: Epoch time: 15.48 s 
2023-03-21 20:26:15.336872: Yayy! New best EMA pseudo Dice: 0.5066 
2023-03-21 20:26:17.147838:  
2023-03-21 20:26:17.148035: Epoch 6 
2023-03-21 20:26:17.148165: Current learning rate: 0.00891 
2023-03-21 20:26:32.702681: train_loss -0.8281 
2023-03-21 20:26:32.703971: val_loss -0.8272 
2023-03-21 20:26:32.704084: Pseudo dice [0.8821, 0.859] 
2023-03-21 20:26:32.704199: Epoch time: 15.56 s 
2023-03-21 20:26:32.704292: Yayy! New best EMA pseudo Dice: 0.543 
2023-03-21 20:26:34.740071:  
2023-03-21 20:26:34.740455: Epoch 7 
2023-03-21 20:26:34.740763: Current learning rate: 0.00873 
2023-03-21 20:26:50.476127: train_loss -0.8305 
2023-03-21 20:26:50.476414: val_loss -0.8376 
2023-03-21 20:26:50.476532: Pseudo dice [0.8888, 0.8688] 
2023-03-21 20:26:50.476652: Epoch time: 15.74 s 
2023-03-21 20:26:50.476750: Yayy! New best EMA pseudo Dice: 0.5766 
2023-03-21 20:26:52.284921:  
2023-03-21 20:26:52.285112: Epoch 8 
2023-03-21 20:26:52.285256: Current learning rate: 0.00855 
2023-03-21 20:27:07.891771: train_loss -0.8344 
2023-03-21 20:27:07.892072: val_loss -0.8305 
2023-03-21 20:27:07.892189: Pseudo dice [0.8839, 0.8624] 
2023-03-21 20:27:07.892303: Epoch time: 15.61 s 
2023-03-21 20:27:07.892403: Yayy! New best EMA pseudo Dice: 0.6062 
2023-03-21 20:27:09.811684:  
2023-03-21 20:27:09.811857: Epoch 9 
2023-03-21 20:27:09.812003: Current learning rate: 0.00836 
2023-03-21 20:27:25.205766: train_loss -0.8373 
2023-03-21 20:27:25.206063: val_loss -0.837 
2023-03-21 20:27:25.206188: Pseudo dice [0.8883, 0.8675] 
2023-03-21 20:27:25.206312: Epoch time: 15.39 s 
2023-03-21 20:27:25.206424: Yayy! New best EMA pseudo Dice: 0.6334 
2023-03-21 20:27:27.319094:  
2023-03-21 20:27:27.319317: Epoch 10 
2023-03-21 20:27:27.319469: Current learning rate: 0.00818 
2023-03-21 20:27:42.636197: train_loss -0.8397 
2023-03-21 20:27:42.636592: val_loss -0.8345 
2023-03-21 20:27:42.636923: Pseudo dice [0.8848, 0.867] 
2023-03-21 20:27:42.637068: Epoch time: 15.32 s 
2023-03-21 20:27:42.637169: Yayy! New best EMA pseudo Dice: 0.6577 
2023-03-21 20:27:44.458432:  
2023-03-21 20:27:44.458673: Epoch 11 
2023-03-21 20:27:44.458833: Current learning rate: 0.008 
2023-03-21 20:27:59.945850: train_loss -0.8424 
2023-03-21 20:27:59.946241: val_loss -0.8404 
2023-03-21 20:27:59.946414: Pseudo dice [0.8904, 0.8691] 
2023-03-21 20:27:59.946576: Epoch time: 15.49 s 
2023-03-21 20:27:59.946739: Yayy! New best EMA pseudo Dice: 0.6799 
2023-03-21 20:28:02.032982:  
2023-03-21 20:28:02.033143: Epoch 12 
2023-03-21 20:28:02.033279: Current learning rate: 0.00781 
2023-03-21 20:28:17.583666: train_loss -0.843 
2023-03-21 20:28:17.584166: val_loss -0.8378 
2023-03-21 20:28:17.584578: Pseudo dice [0.886, 0.871] 
2023-03-21 20:28:17.584856: Epoch time: 15.55 s 
2023-03-21 20:28:17.584993: Yayy! New best EMA pseudo Dice: 0.6997 
2023-03-21 20:28:19.581675:  
2023-03-21 20:28:19.582126: Epoch 13 
2023-03-21 20:28:19.582271: Current learning rate: 0.00763 
2023-03-21 20:28:35.374836: train_loss -0.8471 
2023-03-21 20:28:35.375321: val_loss -0.8387 
2023-03-21 20:28:35.375438: Pseudo dice [0.8889, 0.8696] 
2023-03-21 20:28:35.375576: Epoch time: 15.79 s 
2023-03-21 20:28:35.375680: Yayy! New best EMA pseudo Dice: 0.7177 
2023-03-21 20:28:37.143195:  
2023-03-21 20:28:37.143395: Epoch 14 
2023-03-21 20:28:37.143543: Current learning rate: 0.00744 
2023-03-21 20:28:52.837519: train_loss -0.8483 
2023-03-21 20:28:52.837877: val_loss -0.8442 
2023-03-21 20:28:52.837996: Pseudo dice [0.8945, 0.871] 
2023-03-21 20:28:52.838126: Epoch time: 15.7 s 
2023-03-21 20:28:52.838248: Yayy! New best EMA pseudo Dice: 0.7342 
2023-03-21 20:28:54.746468:  
2023-03-21 20:28:54.746671: Epoch 15 
2023-03-21 20:28:54.746863: Current learning rate: 0.00725 
2023-03-21 20:29:10.478814: train_loss -0.8493 
2023-03-21 20:29:10.479205: val_loss -0.8456 
2023-03-21 20:29:10.479328: Pseudo dice [0.893, 0.8761] 
2023-03-21 20:29:10.479445: Epoch time: 15.73 s 
2023-03-21 20:29:10.479543: Yayy! New best EMA pseudo Dice: 0.7492 
2023-03-21 20:29:12.317167:  
2023-03-21 20:29:12.317487: Epoch 16 
2023-03-21 20:29:12.317723: Current learning rate: 0.00707 
2023-03-21 20:29:28.315085: train_loss -0.8505 
2023-03-21 20:29:28.315936: val_loss -0.8458 
2023-03-21 20:29:28.316061: Pseudo dice [0.8931, 0.8771] 
2023-03-21 20:29:28.316221: Epoch time: 16.0 s 
2023-03-21 20:29:28.316350: Yayy! New best EMA pseudo Dice: 0.7628 
2023-03-21 20:29:30.631347:  
2023-03-21 20:29:30.631734: Epoch 17 
2023-03-21 20:29:30.632053: Current learning rate: 0.00688 
2023-03-21 20:29:46.331522: train_loss -0.8517 
2023-03-21 20:29:46.332066: val_loss -0.8413 
2023-03-21 20:29:46.332244: Pseudo dice [0.8909, 0.8712] 
2023-03-21 20:29:46.332418: Epoch time: 15.7 s 
2023-03-21 20:29:46.332567: Yayy! New best EMA pseudo Dice: 0.7746 
2023-03-21 20:29:48.356230:  
2023-03-21 20:29:48.356566: Epoch 18 
2023-03-21 20:29:48.356823: Current learning rate: 0.00669 
2023-03-21 20:30:04.317768: train_loss -0.8522 
2023-03-21 20:30:04.318216: val_loss -0.84 
2023-03-21 20:30:04.318331: Pseudo dice [0.891, 0.8717] 
2023-03-21 20:30:04.318473: Epoch time: 15.96 s 
2023-03-21 20:30:04.318580: Yayy! New best EMA pseudo Dice: 0.7853 
2023-03-21 20:30:06.442942:  
2023-03-21 20:30:06.443210: Epoch 19 
2023-03-21 20:30:06.443477: Current learning rate: 0.0065 
2023-03-21 20:30:22.583834: train_loss -0.8534 
2023-03-21 20:30:22.584237: val_loss -0.8422 
2023-03-21 20:30:22.584360: Pseudo dice [0.8906, 0.8713] 
2023-03-21 20:30:22.584506: Epoch time: 16.14 s 
2023-03-21 20:30:22.584626: Yayy! New best EMA pseudo Dice: 0.7949 
2023-03-21 20:30:24.426156:  
2023-03-21 20:30:24.426361: Epoch 20 
2023-03-21 20:30:24.426503: Current learning rate: 0.00631 
2023-03-21 20:30:40.203702: train_loss -0.8555 
2023-03-21 20:30:40.204017: val_loss -0.8414 
2023-03-21 20:30:40.204142: Pseudo dice [0.8912, 0.87] 
2023-03-21 20:30:40.204265: Epoch time: 15.78 s 
2023-03-21 20:30:40.204371: Yayy! New best EMA pseudo Dice: 0.8034 
2023-03-21 20:30:42.089898:  
2023-03-21 20:30:42.090067: Epoch 21 
2023-03-21 20:30:42.090215: Current learning rate: 0.00612 
2023-03-21 20:30:57.969416: train_loss -0.8566 
2023-03-21 20:30:57.969752: val_loss -0.852 
2023-03-21 20:30:57.969876: Pseudo dice [0.8992, 0.8788] 
2023-03-21 20:30:57.970000: Epoch time: 15.88 s 
2023-03-21 20:30:57.970109: Yayy! New best EMA pseudo Dice: 0.812 
2023-03-21 20:31:00.114347:  
2023-03-21 20:31:00.114553: Epoch 22 
2023-03-21 20:31:00.114716: Current learning rate: 0.00593 
2023-03-21 20:31:16.144043: train_loss -0.8585 
2023-03-21 20:31:16.144378: val_loss -0.8449 
2023-03-21 20:31:16.144509: Pseudo dice [0.8938, 0.8732] 
2023-03-21 20:31:16.144629: Epoch time: 16.03 s 
2023-03-21 20:31:16.144731: Yayy! New best EMA pseudo Dice: 0.8191 
2023-03-21 20:31:17.941867:  
2023-03-21 20:31:17.942048: Epoch 23 
2023-03-21 20:31:17.942183: Current learning rate: 0.00574 
2023-03-21 20:31:33.814315: train_loss -0.8579 
2023-03-21 20:31:33.814846: val_loss -0.8449 
2023-03-21 20:31:33.815087: Pseudo dice [0.8952, 0.8729] 
2023-03-21 20:31:33.815318: Epoch time: 15.87 s 
2023-03-21 20:31:33.815574: Yayy! New best EMA pseudo Dice: 0.8256 
2023-03-21 20:31:35.528459:  
2023-03-21 20:31:35.528658: Epoch 24 
2023-03-21 20:31:35.528799: Current learning rate: 0.00555 
2023-03-21 20:31:51.529967: train_loss -0.8602 
2023-03-21 20:31:51.530450: val_loss -0.8446 
2023-03-21 20:31:51.531653: Pseudo dice [0.8967, 0.8726] 
2023-03-21 20:31:51.532127: Epoch time: 16.0 s 
2023-03-21 20:31:51.532702: Yayy! New best EMA pseudo Dice: 0.8315 
2023-03-21 20:31:53.296021:  
2023-03-21 20:31:53.296464: Epoch 25 
2023-03-21 20:31:53.296738: Current learning rate: 0.00536 
2023-03-21 20:32:09.268895: train_loss -0.8609 
2023-03-21 20:32:09.269208: val_loss -0.8454 
2023-03-21 20:32:09.269327: Pseudo dice [0.8926, 0.8757] 
2023-03-21 20:32:09.269446: Epoch time: 15.97 s 
2023-03-21 20:32:09.269549: Yayy! New best EMA pseudo Dice: 0.8368 
2023-03-21 20:32:11.495797:  
2023-03-21 20:32:11.496033: Epoch 26 
2023-03-21 20:32:11.496210: Current learning rate: 0.00517 
2023-03-21 20:32:27.230840: train_loss -0.8631 
2023-03-21 20:32:27.231159: val_loss -0.8475 
2023-03-21 20:32:27.231279: Pseudo dice [0.8953, 0.8756] 
2023-03-21 20:32:27.231400: Epoch time: 15.74 s 
2023-03-21 20:32:27.231503: Yayy! New best EMA pseudo Dice: 0.8417 
2023-03-21 20:32:29.013046:  
2023-03-21 20:32:29.013472: Epoch 27 
2023-03-21 20:32:29.013792: Current learning rate: 0.00497 
2023-03-21 20:32:44.863466: train_loss -0.8627 
2023-03-21 20:32:44.863902: val_loss -0.8466 
2023-03-21 20:32:44.864083: Pseudo dice [0.8926, 0.876] 
2023-03-21 20:32:44.864265: Epoch time: 15.85 s 
2023-03-21 20:32:44.864419: Yayy! New best EMA pseudo Dice: 0.8459 
2023-03-21 20:32:46.688080:  
2023-03-21 20:32:46.688254: Epoch 28 
2023-03-21 20:32:46.688393: Current learning rate: 0.00478 
2023-03-21 20:33:02.370866: train_loss -0.8628 
2023-03-21 20:33:02.371548: val_loss -0.8479 
2023-03-21 20:33:02.371666: Pseudo dice [0.8963, 0.8778] 
2023-03-21 20:33:02.371793: Epoch time: 15.68 s 
2023-03-21 20:33:02.371891: Yayy! New best EMA pseudo Dice: 0.85 
2023-03-21 20:33:04.338448:  
2023-03-21 20:33:04.338621: Epoch 29 
2023-03-21 20:33:04.338788: Current learning rate: 0.00458 
2023-03-21 20:33:19.993027: train_loss -0.8642 
2023-03-21 20:33:19.993489: val_loss -0.8499 
2023-03-21 20:33:19.993614: Pseudo dice [0.8968, 0.8775] 
2023-03-21 20:33:19.993761: Epoch time: 15.66 s 
2023-03-21 20:33:19.993886: Yayy! New best EMA pseudo Dice: 0.8538 
2023-03-21 20:33:21.826089:  
2023-03-21 20:33:21.826294: Epoch 30 
2023-03-21 20:33:21.826433: Current learning rate: 0.00438 
2023-03-21 20:33:37.484389: train_loss -0.8657 
2023-03-21 20:33:37.484812: val_loss -0.849 
2023-03-21 20:33:37.484933: Pseudo dice [0.8984, 0.8778] 
2023-03-21 20:33:37.485054: Epoch time: 15.66 s 
2023-03-21 20:33:37.485153: Yayy! New best EMA pseudo Dice: 0.8572 
2023-03-21 20:33:39.704798:  
2023-03-21 20:33:39.705192: Epoch 31 
2023-03-21 20:33:39.705347: Current learning rate: 0.00419 
2023-03-21 20:33:55.545419: train_loss -0.8654 
2023-03-21 20:33:55.546005: val_loss -0.8478 
2023-03-21 20:33:55.546142: Pseudo dice [0.8985, 0.8764] 
2023-03-21 20:33:55.546287: Epoch time: 15.84 s 
2023-03-21 20:33:55.546403: Yayy! New best EMA pseudo Dice: 0.8602 
2023-03-21 20:33:57.439318:  
2023-03-21 20:33:57.439499: Epoch 32 
2023-03-21 20:33:57.439636: Current learning rate: 0.00399 
2023-03-21 20:34:12.969189: train_loss -0.8668 
2023-03-21 20:34:12.969534: val_loss -0.8473 
2023-03-21 20:34:12.969664: Pseudo dice [0.8967, 0.8747] 
2023-03-21 20:34:12.969790: Epoch time: 15.53 s 
2023-03-21 20:34:12.969899: Yayy! New best EMA pseudo Dice: 0.8628 
2023-03-21 20:34:15.014524:  
2023-03-21 20:34:15.014790: Epoch 33 
2023-03-21 20:34:15.014949: Current learning rate: 0.00379 
2023-03-21 20:34:30.529698: train_loss -0.8687 
2023-03-21 20:34:30.530013: val_loss -0.8487 
2023-03-21 20:34:30.530180: Pseudo dice [0.8968, 0.8769] 
2023-03-21 20:34:30.530356: Epoch time: 15.52 s 
2023-03-21 20:34:30.530515: Yayy! New best EMA pseudo Dice: 0.8652 
2023-03-21 20:34:32.407607:  
2023-03-21 20:34:32.407768: Epoch 34 
2023-03-21 20:34:32.407907: Current learning rate: 0.00359 
2023-03-21 20:34:48.079109: train_loss -0.868 
2023-03-21 20:34:48.079760: val_loss -0.846 
2023-03-21 20:34:48.079993: Pseudo dice [0.8958, 0.8734] 
2023-03-21 20:34:48.080317: Epoch time: 15.67 s 
2023-03-21 20:34:48.080669: Yayy! New best EMA pseudo Dice: 0.8671 
2023-03-21 20:34:50.197245:  
2023-03-21 20:34:50.197410: Epoch 35 
2023-03-21 20:34:50.197562: Current learning rate: 0.00338 
2023-03-21 20:35:05.857150: train_loss -0.8692 
2023-03-21 20:35:05.857730: val_loss -0.8458 
2023-03-21 20:35:05.858275: Pseudo dice [0.8961, 0.8761] 
2023-03-21 20:35:05.858593: Epoch time: 15.66 s 
2023-03-21 20:35:05.858949: Yayy! New best EMA pseudo Dice: 0.869 
2023-03-21 20:35:08.301405:  
2023-03-21 20:35:08.301575: Epoch 36 
2023-03-21 20:35:08.301726: Current learning rate: 0.00318 
2023-03-21 20:35:24.093425: train_loss -0.8706 
2023-03-21 20:35:24.093754: val_loss -0.8491 
2023-03-21 20:35:24.094138: Pseudo dice [0.8974, 0.876] 
2023-03-21 20:35:24.094468: Epoch time: 15.79 s 
2023-03-21 20:35:24.094625: Yayy! New best EMA pseudo Dice: 0.8708 
2023-03-21 20:35:26.207313:  
2023-03-21 20:35:26.207678: Epoch 37 
2023-03-21 20:35:26.207952: Current learning rate: 0.00297 
2023-03-21 20:35:41.905427: train_loss -0.871 
2023-03-21 20:35:41.905774: val_loss -0.8462 
2023-03-21 20:35:41.905905: Pseudo dice [0.8959, 0.8769] 
2023-03-21 20:35:41.906034: Epoch time: 15.7 s 
2023-03-21 20:35:41.906139: Yayy! New best EMA pseudo Dice: 0.8723 
2023-03-21 20:35:43.751999:  
2023-03-21 20:35:43.752163: Epoch 38 
2023-03-21 20:35:43.752336: Current learning rate: 0.00277 
2023-03-21 20:35:59.296583: train_loss -0.8712 
2023-03-21 20:35:59.296947: val_loss -0.8497 
2023-03-21 20:35:59.297072: Pseudo dice [0.8966, 0.8785] 
2023-03-21 20:35:59.297198: Epoch time: 15.55 s 
2023-03-21 20:35:59.297308: Yayy! New best EMA pseudo Dice: 0.8739 
2023-03-21 20:36:01.156579:  
2023-03-21 20:36:01.156744: Epoch 39 
2023-03-21 20:36:01.156878: Current learning rate: 0.00256 
2023-03-21 20:36:16.910361: train_loss -0.8706 
2023-03-21 20:36:16.910924: val_loss -0.8504 
2023-03-21 20:36:16.911305: Pseudo dice [0.8979, 0.8797] 
2023-03-21 20:36:16.911937: Epoch time: 15.75 s 
2023-03-21 20:36:16.912090: Yayy! New best EMA pseudo Dice: 0.8754 
2023-03-21 20:36:19.080886:  
2023-03-21 20:36:19.081048: Epoch 40 
2023-03-21 20:36:19.081183: Current learning rate: 0.00235 
2023-03-21 20:36:34.761736: train_loss -0.8732 
2023-03-21 20:36:34.762313: val_loss -0.8476 
2023-03-21 20:36:34.762699: Pseudo dice [0.8971, 0.8769] 
2023-03-21 20:36:34.763252: Epoch time: 15.68 s 
2023-03-21 20:36:34.763447: Yayy! New best EMA pseudo Dice: 0.8765 
2023-03-21 20:36:36.878976:  
2023-03-21 20:36:36.879190: Epoch 41 
2023-03-21 20:36:36.879335: Current learning rate: 0.00214 
2023-03-21 20:36:52.540119: train_loss -0.8731 
2023-03-21 20:36:52.540437: val_loss -0.8448 
2023-03-21 20:36:52.540565: Pseudo dice [0.8935, 0.8733] 
2023-03-21 20:36:52.540686: Epoch time: 15.66 s 
2023-03-21 20:36:52.540810: Yayy! New best EMA pseudo Dice: 0.8772 
2023-03-21 20:36:54.451583:  
2023-03-21 20:36:54.451751: Epoch 42 
2023-03-21 20:36:54.451887: Current learning rate: 0.00192 
2023-03-21 20:37:10.156134: train_loss -0.8742 
2023-03-21 20:37:10.156599: val_loss -0.8491 
2023-03-21 20:37:10.156763: Pseudo dice [0.8968, 0.8771] 
2023-03-21 20:37:10.156923: Epoch time: 15.71 s 
2023-03-21 20:37:10.157073: Yayy! New best EMA pseudo Dice: 0.8782 
2023-03-21 20:37:12.028279:  
2023-03-21 20:37:12.028554: Epoch 43 
2023-03-21 20:37:12.028692: Current learning rate: 0.0017 
2023-03-21 20:37:27.713067: train_loss -0.8756 
2023-03-21 20:37:27.713506: val_loss -0.8525 
2023-03-21 20:37:27.713674: Pseudo dice [0.9011, 0.8807] 
2023-03-21 20:37:27.713835: Epoch time: 15.69 s 
2023-03-21 20:37:27.713972: Yayy! New best EMA pseudo Dice: 0.8795 
2023-03-21 20:37:29.748213:  
2023-03-21 20:37:29.748368: Epoch 44 
2023-03-21 20:37:29.748503: Current learning rate: 0.00148 
2023-03-21 20:37:45.407631: train_loss -0.8742 
2023-03-21 20:37:45.408380: val_loss -0.8496 
2023-03-21 20:37:45.408572: Pseudo dice [0.8984, 0.8788] 
2023-03-21 20:37:45.408851: Epoch time: 15.66 s 
2023-03-21 20:37:45.408966: Yayy! New best EMA pseudo Dice: 0.8804 
2023-03-21 20:37:47.751068:  
2023-03-21 20:37:47.751328: Epoch 45 
2023-03-21 20:37:47.751478: Current learning rate: 0.00126 
2023-03-21 20:38:03.308018: train_loss -0.8771 
2023-03-21 20:38:03.308904: val_loss -0.8503 
2023-03-21 20:38:03.309211: Pseudo dice [0.8983, 0.8795] 
2023-03-21 20:38:03.309422: Epoch time: 15.56 s 
2023-03-21 20:38:03.309688: Yayy! New best EMA pseudo Dice: 0.8812 
2023-03-21 20:38:05.362165:  
2023-03-21 20:38:05.362513: Epoch 46 
2023-03-21 20:38:05.362663: Current learning rate: 0.00103 
2023-03-21 20:38:20.802520: train_loss -0.8756 
2023-03-21 20:38:20.802949: val_loss -0.8485 
2023-03-21 20:38:20.803221: Pseudo dice [0.8959, 0.8778] 
2023-03-21 20:38:20.803614: Epoch time: 15.44 s 
2023-03-21 20:38:20.803962: Yayy! New best EMA pseudo Dice: 0.8818 
2023-03-21 20:38:22.836975:  
2023-03-21 20:38:22.837173: Epoch 47 
2023-03-21 20:38:22.837325: Current learning rate: 0.00079 
2023-03-21 20:38:38.780185: train_loss -0.8778 
2023-03-21 20:38:38.780577: val_loss -0.8507 
2023-03-21 20:38:38.780735: Pseudo dice [0.8991, 0.8774] 
2023-03-21 20:38:38.780904: Epoch time: 15.94 s 
2023-03-21 20:38:38.781038: Yayy! New best EMA pseudo Dice: 0.8824 
2023-03-21 20:38:40.673477:  
2023-03-21 20:38:40.673706: Epoch 48 
2023-03-21 20:38:40.673854: Current learning rate: 0.00055 
2023-03-21 20:38:56.337410: train_loss -0.879 
2023-03-21 20:38:56.337731: val_loss -0.8497 
2023-03-21 20:38:56.337853: Pseudo dice [0.8971, 0.8793] 
2023-03-21 20:38:56.337974: Epoch time: 15.66 s 
2023-03-21 20:38:56.338073: Yayy! New best EMA pseudo Dice: 0.883 
2023-03-21 20:38:58.077475:  
2023-03-21 20:38:58.077640: Epoch 49 
2023-03-21 20:38:58.077798: Current learning rate: 0.0003 
2023-03-21 20:39:12.861596: train_loss -0.8781 
2023-03-21 20:39:12.861919: val_loss -0.85 
2023-03-21 20:39:12.862052: Pseudo dice [0.8986, 0.8773] 
2023-03-21 20:39:12.862193: Epoch time: 14.78 s 
2023-03-21 20:39:12.862305: Yayy! New best EMA pseudo Dice: 0.8835 
2023-03-21 20:39:15.481406: Using splits from existing split file: /data_hdd/users/zengzhilin/nnUNet_preprocessed/Dataset004_Hippocampus/splits_final.json 
2023-03-21 20:39:15.482207: The split file contains 5 splits. 
2023-03-21 20:39:15.482285: Desired fold for training: 2 
2023-03-21 20:39:15.482359: This split has 208 training and 52 validation cases. 
2023-03-21 20:39:15.482867: predicting hippocampus_004 
2023-03-21 20:39:15.693592: predicting hippocampus_007 
2023-03-21 20:39:15.748539: predicting hippocampus_015 
2023-03-21 20:39:15.944102: predicting hippocampus_024 
2023-03-21 20:39:15.996757: predicting hippocampus_041 
2023-03-21 20:39:16.067644: predicting hippocampus_042 
2023-03-21 20:39:16.165591: predicting hippocampus_046 
2023-03-21 20:39:16.256635: predicting hippocampus_056 
2023-03-21 20:39:16.572976: predicting hippocampus_068 
2023-03-21 20:39:16.671985: predicting hippocampus_074 
2023-03-21 20:39:16.876799: predicting hippocampus_084 
2023-03-21 20:39:16.949003: predicting hippocampus_089 
2023-03-21 20:39:17.059747: predicting hippocampus_098 
2023-03-21 20:39:17.147825: predicting hippocampus_099 
2023-03-21 20:39:17.203888: predicting hippocampus_133 
2023-03-21 20:39:17.305807: predicting hippocampus_135 
2023-03-21 20:39:17.365918: predicting hippocampus_143 
2023-03-21 20:39:19.478807: predicting hippocampus_145 
2023-03-21 20:39:19.537457: predicting hippocampus_150 
2023-03-21 20:39:19.594940: predicting hippocampus_156 
2023-03-21 20:39:19.648097: predicting hippocampus_158 
2023-03-21 20:39:19.701322: predicting hippocampus_161 
2023-03-21 20:39:19.760535: predicting hippocampus_165 
2023-03-21 20:39:19.838269: predicting hippocampus_174 
2023-03-21 20:39:19.912198: predicting hippocampus_176 
2023-03-21 20:39:19.986706: predicting hippocampus_199 
2023-03-21 20:39:20.051761: predicting hippocampus_220 
2023-03-21 20:39:20.119075: predicting hippocampus_221 
2023-03-21 20:39:20.183891: predicting hippocampus_224 
2023-03-21 20:39:20.240464: predicting hippocampus_225 
2023-03-21 20:39:20.307419: predicting hippocampus_232 
2023-03-21 20:39:20.425178: predicting hippocampus_251 
2023-03-21 20:39:20.541019: predicting hippocampus_252 
2023-03-21 20:39:20.598314: predicting hippocampus_257 
2023-03-21 20:39:20.652844: predicting hippocampus_259 
2023-03-21 20:39:20.709647: predicting hippocampus_265 
2023-03-21 20:39:20.762340: predicting hippocampus_276 
2023-03-21 20:39:20.816328: predicting hippocampus_279 
2023-03-21 20:39:20.870154: predicting hippocampus_297 
2023-03-21 20:39:20.923102: predicting hippocampus_302 
2023-03-21 20:39:20.977286: predicting hippocampus_304 
2023-03-21 20:39:21.029030: predicting hippocampus_311 
2023-03-21 20:39:21.082897: predicting hippocampus_320 
2023-03-21 20:39:21.136976: predicting hippocampus_325 
2023-03-21 20:39:21.186646: predicting hippocampus_343 
2023-03-21 20:39:21.238059: predicting hippocampus_366 
2023-03-21 20:39:21.290104: predicting hippocampus_370 
2023-03-21 20:39:21.343366: predicting hippocampus_372 
2023-03-21 20:39:21.397718: predicting hippocampus_373 
2023-03-21 20:39:21.448948: predicting hippocampus_378 
2023-03-21 20:39:21.500550: predicting hippocampus_383 
2023-03-21 20:39:21.553105: predicting hippocampus_387 
2023-03-21 20:39:25.722982: Validation complete 
2023-03-21 20:39:25.723183: Mean Validation Dice:  0.8923777886833665 
