
This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'num_pool_per_axis': [3, 3, 3], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2023-03-21 20:24:37.042666: unpacking dataset... 
2023-03-21 20:24:41.260322: unpacking done... 
2023-03-21 20:24:41.262816: do_dummy_2d_data_aug: False 
2023-03-21 20:24:41.268008: Using splits from existing split file: /data_hdd/users/zengzhilin/nnUNet_preprocessed/Dataset004_Hippocampus/splits_final.json 
2023-03-21 20:24:41.268897: The split file contains 5 splits. 
2023-03-21 20:24:41.269044: Desired fold for training: 3 
2023-03-21 20:24:41.269161: This split has 208 training and 52 validation cases. 
2023-03-21 20:24:41.378541: Unable to plot network architecture: 
2023-03-21 20:24:41.378812: No module named 'hiddenlayer' 
2023-03-21 20:24:41.487499:  
2023-03-21 20:24:41.487654: Epoch 0 
2023-03-21 20:24:41.487901: Current learning rate: 0.01 
2023-03-21 20:25:03.817277: train_loss -0.3065 
2023-03-21 20:25:03.817608: val_loss -0.7291 
2023-03-21 20:25:03.817742: Pseudo dice [0.8112, 0.8028] 
2023-03-21 20:25:03.817881: Epoch time: 22.33 s 
2023-03-21 20:25:03.817981: Yayy! New best EMA pseudo Dice: 0.807 
2023-03-21 20:25:05.334809:  
2023-03-21 20:25:05.334960: Epoch 1 
2023-03-21 20:25:05.335096: Current learning rate: 0.00982 
2023-03-21 20:25:21.032432: train_loss -0.7552 
2023-03-21 20:25:21.032783: val_loss -0.798 
2023-03-21 20:25:21.032917: Pseudo dice [0.8595, 0.8473] 
2023-03-21 20:25:21.033035: Epoch time: 15.7 s 
2023-03-21 20:25:21.033160: Yayy! New best EMA pseudo Dice: 0.8116 
2023-03-21 20:25:22.831126:  
2023-03-21 20:25:22.831432: Epoch 2 
2023-03-21 20:25:22.831685: Current learning rate: 0.00964 
2023-03-21 20:25:38.696458: train_loss -0.7907 
2023-03-21 20:25:38.696737: val_loss -0.8102 
2023-03-21 20:25:38.696865: Pseudo dice [0.8674, 0.8547] 
2023-03-21 20:25:38.696990: Epoch time: 15.87 s 
2023-03-21 20:25:38.697092: Yayy! New best EMA pseudo Dice: 0.8166 
2023-03-21 20:25:40.732949:  
2023-03-21 20:25:40.733113: Epoch 3 
2023-03-21 20:25:40.733236: Current learning rate: 0.00946 
2023-03-21 20:25:56.367471: train_loss -0.8036 
2023-03-21 20:25:56.367932: val_loss -0.8232 
2023-03-21 20:25:56.368176: Pseudo dice [0.8744, 0.8667] 
2023-03-21 20:25:56.368644: Epoch time: 15.64 s 
2023-03-21 20:25:56.368774: Yayy! New best EMA pseudo Dice: 0.822 
2023-03-21 20:25:58.201403:  
2023-03-21 20:25:58.201647: Epoch 4 
2023-03-21 20:25:58.201780: Current learning rate: 0.00928 
2023-03-21 20:26:14.180769: train_loss -0.8109 
2023-03-21 20:26:14.181487: val_loss -0.8288 
2023-03-21 20:26:14.181645: Pseudo dice [0.8835, 0.8654] 
2023-03-21 20:26:14.181793: Epoch time: 15.98 s 
2023-03-21 20:26:14.181905: Yayy! New best EMA pseudo Dice: 0.8272 
2023-03-21 20:26:16.208107:  
2023-03-21 20:26:16.208267: Epoch 5 
2023-03-21 20:26:16.208407: Current learning rate: 0.0091 
2023-03-21 20:26:32.089168: train_loss -0.8213 
2023-03-21 20:26:32.089460: val_loss -0.829 
2023-03-21 20:26:32.089606: Pseudo dice [0.8814, 0.8668] 
2023-03-21 20:26:32.089745: Epoch time: 15.88 s 
2023-03-21 20:26:32.089854: Yayy! New best EMA pseudo Dice: 0.8319 
2023-03-21 20:26:33.877429:  
2023-03-21 20:26:33.877697: Epoch 6 
2023-03-21 20:26:33.877946: Current learning rate: 0.00891 
2023-03-21 20:26:49.845465: train_loss -0.825 
2023-03-21 20:26:49.845910: val_loss -0.8359 
2023-03-21 20:26:49.846052: Pseudo dice [0.8876, 0.8717] 
2023-03-21 20:26:49.846199: Epoch time: 15.97 s 
2023-03-21 20:26:49.846312: Yayy! New best EMA pseudo Dice: 0.8367 
2023-03-21 20:26:51.612292:  
2023-03-21 20:26:51.612726: Epoch 7 
2023-03-21 20:26:51.612990: Current learning rate: 0.00873 
2023-03-21 20:27:07.233557: train_loss -0.8292 
2023-03-21 20:27:07.233908: val_loss -0.8372 
2023-03-21 20:27:07.234040: Pseudo dice [0.8883, 0.8729] 
2023-03-21 20:27:07.234161: Epoch time: 15.62 s 
2023-03-21 20:27:07.234262: Yayy! New best EMA pseudo Dice: 0.8411 
2023-03-21 20:27:09.291109:  
2023-03-21 20:27:09.291296: Epoch 8 
2023-03-21 20:27:09.291444: Current learning rate: 0.00855 
2023-03-21 20:27:25.348012: train_loss -0.8347 
2023-03-21 20:27:25.349879: val_loss -0.8237 
2023-03-21 20:27:25.350023: Pseudo dice [0.8746, 0.8646] 
2023-03-21 20:27:25.350167: Epoch time: 16.06 s 
2023-03-21 20:27:25.350279: Yayy! New best EMA pseudo Dice: 0.8439 
2023-03-21 20:27:27.282939:  
2023-03-21 20:27:27.283102: Epoch 9 
2023-03-21 20:27:27.283229: Current learning rate: 0.00836 
2023-03-21 20:27:43.132507: train_loss -0.8346 
2023-03-21 20:27:43.132833: val_loss -0.8371 
2023-03-21 20:27:43.132957: Pseudo dice [0.8865, 0.8741] 
2023-03-21 20:27:43.133070: Epoch time: 15.85 s 
2023-03-21 20:27:43.133269: Yayy! New best EMA pseudo Dice: 0.8476 
2023-03-21 20:27:44.915578:  
2023-03-21 20:27:44.915741: Epoch 10 
2023-03-21 20:27:44.915885: Current learning rate: 0.00818 
2023-03-21 20:28:00.468734: train_loss -0.8397 
2023-03-21 20:28:00.469036: val_loss -0.8406 
2023-03-21 20:28:00.469167: Pseudo dice [0.8906, 0.8737] 
2023-03-21 20:28:00.469291: Epoch time: 15.55 s 
2023-03-21 20:28:00.469397: Yayy! New best EMA pseudo Dice: 0.851 
2023-03-21 20:28:02.286942:  
2023-03-21 20:28:02.287112: Epoch 11 
2023-03-21 20:28:02.287244: Current learning rate: 0.008 
2023-03-21 20:28:18.150435: train_loss -0.8406 
2023-03-21 20:28:18.150856: val_loss -0.8416 
2023-03-21 20:28:18.151017: Pseudo dice [0.89, 0.8753] 
2023-03-21 20:28:18.151237: Epoch time: 15.86 s 
2023-03-21 20:28:18.151422: Yayy! New best EMA pseudo Dice: 0.8542 
2023-03-21 20:28:19.905638:  
2023-03-21 20:28:19.906049: Epoch 12 
2023-03-21 20:28:19.906297: Current learning rate: 0.00781 
2023-03-21 20:28:35.520092: train_loss -0.8428 
2023-03-21 20:28:35.520381: val_loss -0.8397 
2023-03-21 20:28:35.520504: Pseudo dice [0.8871, 0.876] 
2023-03-21 20:28:35.520622: Epoch time: 15.62 s 
2023-03-21 20:28:35.520726: Yayy! New best EMA pseudo Dice: 0.8569 
2023-03-21 20:28:37.506691:  
2023-03-21 20:28:37.509518: Epoch 13 
2023-03-21 20:28:37.509665: Current learning rate: 0.00763 
2023-03-21 20:28:53.382910: train_loss -0.8464 
2023-03-21 20:28:53.383583: val_loss -0.8401 
2023-03-21 20:28:53.383941: Pseudo dice [0.8889, 0.8739] 
2023-03-21 20:28:53.384065: Epoch time: 15.88 s 
2023-03-21 20:28:53.384319: Yayy! New best EMA pseudo Dice: 0.8594 
2023-03-21 20:28:55.220923:  
2023-03-21 20:28:55.221081: Epoch 14 
2023-03-21 20:28:55.221215: Current learning rate: 0.00744 
2023-03-21 20:29:11.111085: train_loss -0.8473 
2023-03-21 20:29:11.111414: val_loss -0.8433 
2023-03-21 20:29:11.111538: Pseudo dice [0.8903, 0.8758] 
2023-03-21 20:29:11.111655: Epoch time: 15.89 s 
2023-03-21 20:29:11.111756: Yayy! New best EMA pseudo Dice: 0.8617 
2023-03-21 20:29:13.059641:  
2023-03-21 20:29:13.059837: Epoch 15 
2023-03-21 20:29:13.060024: Current learning rate: 0.00725 
2023-03-21 20:29:29.071515: train_loss -0.8499 
2023-03-21 20:29:29.072090: val_loss -0.8461 
2023-03-21 20:29:29.072250: Pseudo dice [0.8941, 0.8797] 
2023-03-21 20:29:29.072417: Epoch time: 16.01 s 
2023-03-21 20:29:29.072587: Yayy! New best EMA pseudo Dice: 0.8643 
2023-03-21 20:29:30.922861:  
2023-03-21 20:29:30.923077: Epoch 16 
2023-03-21 20:29:30.923212: Current learning rate: 0.00707 
2023-03-21 20:29:46.687722: train_loss -0.8494 
2023-03-21 20:29:46.688026: val_loss -0.8446 
2023-03-21 20:29:46.688197: Pseudo dice [0.8929, 0.8787] 
2023-03-21 20:29:46.688367: Epoch time: 15.77 s 
2023-03-21 20:29:46.688519: Yayy! New best EMA pseudo Dice: 0.8664 
2023-03-21 20:29:48.526905:  
2023-03-21 20:29:48.527197: Epoch 17 
2023-03-21 20:29:48.527428: Current learning rate: 0.00688 
2023-03-21 20:30:04.399690: train_loss -0.8481 
2023-03-21 20:30:04.400050: val_loss -0.8429 
2023-03-21 20:30:04.400182: Pseudo dice [0.8918, 0.876] 
2023-03-21 20:30:04.400307: Epoch time: 15.87 s 
2023-03-21 20:30:04.400411: Yayy! New best EMA pseudo Dice: 0.8682 
2023-03-21 20:30:06.459368:  
2023-03-21 20:30:06.459568: Epoch 18 
2023-03-21 20:30:06.459708: Current learning rate: 0.00669 
2023-03-21 20:30:22.216583: train_loss -0.8512 
2023-03-21 20:30:22.217017: val_loss -0.8469 
2023-03-21 20:30:22.217229: Pseudo dice [0.8948, 0.8783] 
2023-03-21 20:30:22.217431: Epoch time: 15.76 s 
2023-03-21 20:30:22.217575: Yayy! New best EMA pseudo Dice: 0.87 
2023-03-21 20:30:24.068848:  
2023-03-21 20:30:24.069053: Epoch 19 
2023-03-21 20:30:24.069220: Current learning rate: 0.0065 
2023-03-21 20:30:39.973194: train_loss -0.8551 
2023-03-21 20:30:39.973699: val_loss -0.8451 
2023-03-21 20:30:39.974071: Pseudo dice [0.8954, 0.8764] 
2023-03-21 20:30:39.974450: Epoch time: 15.91 s 
2023-03-21 20:30:39.974752: Yayy! New best EMA pseudo Dice: 0.8716 
2023-03-21 20:30:41.843524:  
2023-03-21 20:30:41.843676: Epoch 20 
2023-03-21 20:30:41.843819: Current learning rate: 0.00631 
2023-03-21 20:30:57.575435: train_loss -0.8554 
2023-03-21 20:30:57.575667: val_loss -0.8482 
2023-03-21 20:30:57.576048: Pseudo dice [0.898, 0.8784] 
2023-03-21 20:30:57.576173: Epoch time: 15.73 s 
2023-03-21 20:30:57.576280: Yayy! New best EMA pseudo Dice: 0.8733 
2023-03-21 20:30:59.434363:  
2023-03-21 20:30:59.434587: Epoch 21 
2023-03-21 20:30:59.434790: Current learning rate: 0.00612 
2023-03-21 20:31:15.028885: train_loss -0.8549 
2023-03-21 20:31:15.029300: val_loss -0.8417 
2023-03-21 20:31:15.029488: Pseudo dice [0.8901, 0.8753] 
2023-03-21 20:31:15.029665: Epoch time: 15.6 s 
2023-03-21 20:31:15.029810: Yayy! New best EMA pseudo Dice: 0.8742 
2023-03-21 20:31:16.807671:  
2023-03-21 20:31:16.807870: Epoch 22 
2023-03-21 20:31:16.808008: Current learning rate: 0.00593 
2023-03-21 20:31:32.285303: train_loss -0.8567 
2023-03-21 20:31:32.285705: val_loss -0.8433 
2023-03-21 20:31:32.285845: Pseudo dice [0.8904, 0.8767] 
2023-03-21 20:31:32.285995: Epoch time: 15.48 s 
2023-03-21 20:31:32.286122: Yayy! New best EMA pseudo Dice: 0.8751 
2023-03-21 20:31:34.402969:  
2023-03-21 20:31:34.403161: Epoch 23 
2023-03-21 20:31:34.403294: Current learning rate: 0.00574 
2023-03-21 20:31:49.771039: train_loss -0.8595 
2023-03-21 20:31:49.771564: val_loss -0.8495 
2023-03-21 20:31:49.771765: Pseudo dice [0.8937, 0.8789] 
2023-03-21 20:31:49.771980: Epoch time: 15.37 s 
2023-03-21 20:31:49.772150: Yayy! New best EMA pseudo Dice: 0.8762 
2023-03-21 20:31:51.560773:  
2023-03-21 20:31:51.560928: Epoch 24 
2023-03-21 20:31:51.561081: Current learning rate: 0.00555 
2023-03-21 20:32:07.373969: train_loss -0.8609 
2023-03-21 20:32:07.374568: val_loss -0.8484 
2023-03-21 20:32:07.374954: Pseudo dice [0.8963, 0.8789] 
2023-03-21 20:32:07.375148: Epoch time: 15.81 s 
2023-03-21 20:32:07.375381: Yayy! New best EMA pseudo Dice: 0.8774 
2023-03-21 20:32:09.332676:  
2023-03-21 20:32:09.332839: Epoch 25 
2023-03-21 20:32:09.332996: Current learning rate: 0.00536 
2023-03-21 20:32:24.901868: train_loss -0.8619 
2023-03-21 20:32:24.902194: val_loss -0.8456 
2023-03-21 20:32:24.902332: Pseudo dice [0.895, 0.8764] 
2023-03-21 20:32:24.902465: Epoch time: 15.57 s 
2023-03-21 20:32:24.902573: Yayy! New best EMA pseudo Dice: 0.8782 
2023-03-21 20:32:26.705593:  
2023-03-21 20:32:26.705753: Epoch 26 
2023-03-21 20:32:26.705897: Current learning rate: 0.00517 
2023-03-21 20:32:42.200103: train_loss -0.8595 
2023-03-21 20:32:42.200559: val_loss -0.851 
2023-03-21 20:32:42.200740: Pseudo dice [0.8975, 0.8806] 
2023-03-21 20:32:42.200931: Epoch time: 15.5 s 
2023-03-21 20:32:42.201086: Yayy! New best EMA pseudo Dice: 0.8793 
2023-03-21 20:32:44.081962:  
2023-03-21 20:32:44.082180: Epoch 27 
2023-03-21 20:32:44.082321: Current learning rate: 0.00497 
2023-03-21 20:32:59.713179: train_loss -0.8616 
2023-03-21 20:32:59.713531: val_loss -0.8457 
2023-03-21 20:32:59.713985: Pseudo dice [0.8919, 0.8763] 
2023-03-21 20:32:59.714117: Epoch time: 15.63 s 
2023-03-21 20:32:59.714219: Yayy! New best EMA pseudo Dice: 0.8798 
2023-03-21 20:33:01.875593:  
2023-03-21 20:33:01.875946: Epoch 28 
2023-03-21 20:33:01.876129: Current learning rate: 0.00478 
2023-03-21 20:33:17.739908: train_loss -0.8636 
2023-03-21 20:33:17.740500: val_loss -0.8527 
2023-03-21 20:33:17.741045: Pseudo dice [0.8996, 0.8811] 
2023-03-21 20:33:17.741312: Epoch time: 15.87 s 
2023-03-21 20:33:17.741594: Yayy! New best EMA pseudo Dice: 0.8808 
2023-03-21 20:33:19.632037:  
2023-03-21 20:33:19.632255: Epoch 29 
2023-03-21 20:33:19.632399: Current learning rate: 0.00458 
2023-03-21 20:33:35.087418: train_loss -0.8643 
2023-03-21 20:33:35.087873: val_loss -0.8472 
2023-03-21 20:33:35.088314: Pseudo dice [0.8945, 0.8787] 
2023-03-21 20:33:35.088445: Epoch time: 15.46 s 
2023-03-21 20:33:35.088566: Yayy! New best EMA pseudo Dice: 0.8814 
2023-03-21 20:33:37.079159:  
2023-03-21 20:33:37.079436: Epoch 30 
2023-03-21 20:33:37.079569: Current learning rate: 0.00438 
2023-03-21 20:33:52.608016: train_loss -0.866 
2023-03-21 20:33:52.608346: val_loss -0.8457 
2023-03-21 20:33:52.608726: Pseudo dice [0.895, 0.8777] 
2023-03-21 20:33:52.608904: Epoch time: 15.53 s 
2023-03-21 20:33:52.609066: Yayy! New best EMA pseudo Dice: 0.8819 
2023-03-21 20:33:54.499152:  
2023-03-21 20:33:54.499330: Epoch 31 
2023-03-21 20:33:54.499477: Current learning rate: 0.00419 
2023-03-21 20:34:10.200639: train_loss -0.8681 
2023-03-21 20:34:10.201057: val_loss -0.8527 
2023-03-21 20:34:10.201257: Pseudo dice [0.8991, 0.8826] 
2023-03-21 20:34:10.201480: Epoch time: 15.7 s 
2023-03-21 20:34:10.201593: Yayy! New best EMA pseudo Dice: 0.8828 
2023-03-21 20:34:12.495751:  
2023-03-21 20:34:12.495922: Epoch 32 
2023-03-21 20:34:12.496058: Current learning rate: 0.00399 
2023-03-21 20:34:28.049009: train_loss -0.8664 
2023-03-21 20:34:28.049545: val_loss -0.8488 
2023-03-21 20:34:28.049936: Pseudo dice [0.8965, 0.8789] 
2023-03-21 20:34:28.050227: Epoch time: 15.55 s 
2023-03-21 20:34:28.050362: Yayy! New best EMA pseudo Dice: 0.8833 
2023-03-21 20:34:29.912612:  
2023-03-21 20:34:29.912863: Epoch 33 
2023-03-21 20:34:29.913046: Current learning rate: 0.00379 
2023-03-21 20:34:45.625277: train_loss -0.866 
2023-03-21 20:34:45.625590: val_loss -0.8478 
2023-03-21 20:34:45.625721: Pseudo dice [0.8957, 0.8785] 
2023-03-21 20:34:45.625847: Epoch time: 15.71 s 
2023-03-21 20:34:45.625949: Yayy! New best EMA pseudo Dice: 0.8837 
2023-03-21 20:34:47.439476:  
2023-03-21 20:34:47.439637: Epoch 34 
2023-03-21 20:34:47.439761: Current learning rate: 0.00359 
2023-03-21 20:35:03.246679: train_loss -0.8674 
2023-03-21 20:35:03.247187: val_loss -0.8478 
2023-03-21 20:35:03.247377: Pseudo dice [0.8947, 0.8802] 
2023-03-21 20:35:03.247496: Epoch time: 15.81 s 
2023-03-21 20:35:03.247599: Yayy! New best EMA pseudo Dice: 0.884 
2023-03-21 20:35:05.140172:  
2023-03-21 20:35:05.140346: Epoch 35 
2023-03-21 20:35:05.140481: Current learning rate: 0.00338 
2023-03-21 20:35:21.130530: train_loss -0.8698 
2023-03-21 20:35:21.130941: val_loss -0.8478 
2023-03-21 20:35:21.131208: Pseudo dice [0.8968, 0.8785] 
2023-03-21 20:35:21.131461: Epoch time: 15.99 s 
2023-03-21 20:35:21.131731: Yayy! New best EMA pseudo Dice: 0.8844 
2023-03-21 20:35:23.003484:  
2023-03-21 20:35:23.003646: Epoch 36 
2023-03-21 20:35:23.003775: Current learning rate: 0.00318 
2023-03-21 20:35:38.265189: train_loss -0.8705 
2023-03-21 20:35:38.265485: val_loss -0.8475 
2023-03-21 20:35:38.265618: Pseudo dice [0.8956, 0.8797] 
2023-03-21 20:35:38.265746: Epoch time: 15.26 s 
2023-03-21 20:35:38.265865: Yayy! New best EMA pseudo Dice: 0.8847 
2023-03-21 20:35:40.184010:  
2023-03-21 20:35:40.184168: Epoch 37 
2023-03-21 20:35:40.184322: Current learning rate: 0.00297 
2023-03-21 20:35:55.782305: train_loss -0.8707 
2023-03-21 20:35:55.782634: val_loss -0.8442 
2023-03-21 20:35:55.782769: Pseudo dice [0.8937, 0.8756] 
2023-03-21 20:35:55.782904: Epoch time: 15.6 s 
2023-03-21 20:35:57.544008:  
2023-03-21 20:35:57.544185: Epoch 38 
2023-03-21 20:35:57.544329: Current learning rate: 0.00277 
2023-03-21 20:36:13.187711: train_loss -0.8705 
2023-03-21 20:36:13.188082: val_loss -0.846 
2023-03-21 20:36:13.188341: Pseudo dice [0.8946, 0.8763] 
2023-03-21 20:36:13.188576: Epoch time: 15.64 s 
2023-03-21 20:36:13.188808: Yayy! New best EMA pseudo Dice: 0.8848 
2023-03-21 20:36:15.079582:  
2023-03-21 20:36:15.079845: Epoch 39 
2023-03-21 20:36:15.079993: Current learning rate: 0.00256 
2023-03-21 20:36:30.723855: train_loss -0.8724 
2023-03-21 20:36:30.724157: val_loss -0.8477 
2023-03-21 20:36:30.724294: Pseudo dice [0.8948, 0.8777] 
2023-03-21 20:36:30.724422: Epoch time: 15.65 s 
2023-03-21 20:36:30.724529: Yayy! New best EMA pseudo Dice: 0.8849 
2023-03-21 20:36:32.619038:  
2023-03-21 20:36:32.619228: Epoch 40 
2023-03-21 20:36:32.619375: Current learning rate: 0.00235 
2023-03-21 20:36:48.217764: train_loss -0.8729 
2023-03-21 20:36:48.218085: val_loss -0.8464 
2023-03-21 20:36:48.218251: Pseudo dice [0.8942, 0.8786] 
2023-03-21 20:36:48.218424: Epoch time: 15.6 s 
2023-03-21 20:36:48.218562: Yayy! New best EMA pseudo Dice: 0.8851 
2023-03-21 20:36:50.110216:  
2023-03-21 20:36:50.110407: Epoch 41 
2023-03-21 20:36:50.110536: Current learning rate: 0.00214 
2023-03-21 20:37:06.012424: train_loss -0.8737 
2023-03-21 20:37:06.012852: val_loss -0.8478 
2023-03-21 20:37:06.013046: Pseudo dice [0.8962, 0.8799] 
2023-03-21 20:37:06.013227: Epoch time: 15.9 s 
2023-03-21 20:37:06.013391: Yayy! New best EMA pseudo Dice: 0.8854 
2023-03-21 20:37:08.225764:  
2023-03-21 20:37:08.225946: Epoch 42 
2023-03-21 20:37:08.226088: Current learning rate: 0.00192 
2023-03-21 20:37:23.967329: train_loss -0.8746 
2023-03-21 20:37:23.967648: val_loss -0.8449 
2023-03-21 20:37:23.967781: Pseudo dice [0.8944, 0.877] 
2023-03-21 20:37:23.967914: Epoch time: 15.74 s 
2023-03-21 20:37:23.968019: Yayy! New best EMA pseudo Dice: 0.8854 
2023-03-21 20:37:26.024232:  
2023-03-21 20:37:26.024554: Epoch 43 
2023-03-21 20:37:26.024735: Current learning rate: 0.0017 
2023-03-21 20:37:41.793856: train_loss -0.8761 
2023-03-21 20:37:41.794170: val_loss -0.8491 
2023-03-21 20:37:41.794299: Pseudo dice [0.8972, 0.8787] 
2023-03-21 20:37:41.794607: Epoch time: 15.77 s 
2023-03-21 20:37:41.794711: Yayy! New best EMA pseudo Dice: 0.8857 
2023-03-21 20:37:43.582788:  
2023-03-21 20:37:43.583091: Epoch 44 
2023-03-21 20:37:43.583352: Current learning rate: 0.00148 
2023-03-21 20:37:59.303935: train_loss -0.8757 
2023-03-21 20:37:59.304346: val_loss -0.8494 
2023-03-21 20:37:59.304521: Pseudo dice [0.8959, 0.8808] 
2023-03-21 20:37:59.304699: Epoch time: 15.72 s 
2023-03-21 20:37:59.304836: Yayy! New best EMA pseudo Dice: 0.8859 
2023-03-21 20:38:01.182437:  
2023-03-21 20:38:01.182709: Epoch 45 
2023-03-21 20:38:01.182936: Current learning rate: 0.00126 
2023-03-21 20:38:16.983179: train_loss -0.8751 
2023-03-21 20:38:16.983481: val_loss -0.847 
2023-03-21 20:38:16.983610: Pseudo dice [0.8953, 0.8791] 
2023-03-21 20:38:16.983753: Epoch time: 15.8 s 
2023-03-21 20:38:16.983857: Yayy! New best EMA pseudo Dice: 0.8861 
2023-03-21 20:38:18.740202:  
2023-03-21 20:38:18.740432: Epoch 46 
2023-03-21 20:38:18.740573: Current learning rate: 0.00103 
2023-03-21 20:38:34.698630: train_loss -0.8779 
2023-03-21 20:38:34.699049: val_loss -0.8501 
2023-03-21 20:38:34.699241: Pseudo dice [0.898, 0.8813] 
2023-03-21 20:38:34.699419: Epoch time: 15.96 s 
2023-03-21 20:38:34.699567: Yayy! New best EMA pseudo Dice: 0.8864 
2023-03-21 20:38:37.021064:  
2023-03-21 20:38:37.021210: Epoch 47 
2023-03-21 20:38:37.021344: Current learning rate: 0.00079 
2023-03-21 20:38:52.983895: train_loss -0.8776 
2023-03-21 20:38:52.984265: val_loss -0.849 
2023-03-21 20:38:52.984447: Pseudo dice [0.8969, 0.879] 
2023-03-21 20:38:52.984610: Epoch time: 15.96 s 
2023-03-21 20:38:52.984754: Yayy! New best EMA pseudo Dice: 0.8866 
2023-03-21 20:38:55.361933:  
2023-03-21 20:38:55.362118: Epoch 48 
2023-03-21 20:38:55.362250: Current learning rate: 0.00055 
2023-03-21 20:39:10.400210: train_loss -0.8777 
2023-03-21 20:39:10.400743: val_loss -0.8458 
2023-03-21 20:39:10.400998: Pseudo dice [0.8941, 0.8768] 
2023-03-21 20:39:10.401341: Epoch time: 15.04 s 
2023-03-21 20:39:11.782548:  
2023-03-21 20:39:11.782764: Epoch 49 
2023-03-21 20:39:11.782893: Current learning rate: 0.0003 
2023-03-21 20:39:27.300991: train_loss -0.8773 
2023-03-21 20:39:27.301305: val_loss -0.8485 
2023-03-21 20:39:27.301446: Pseudo dice [0.8956, 0.8798] 
2023-03-21 20:39:27.301562: Epoch time: 15.52 s 
2023-03-21 20:39:27.301676: Yayy! New best EMA pseudo Dice: 0.8866 
2023-03-21 20:39:29.492873: Using splits from existing split file: /data_hdd/users/zengzhilin/nnUNet_preprocessed/Dataset004_Hippocampus/splits_final.json 
2023-03-21 20:39:29.493613: The split file contains 5 splits. 
2023-03-21 20:39:29.493684: Desired fold for training: 3 
2023-03-21 20:39:29.493750: This split has 208 training and 52 validation cases. 
2023-03-21 20:39:29.494254: predicting hippocampus_001 
2023-03-21 20:39:29.726381: predicting hippocampus_006 
2023-03-21 20:39:29.781675: predicting hippocampus_011 
2023-03-21 20:39:29.843248: predicting hippocampus_023 
2023-03-21 20:39:29.985647: predicting hippocampus_038 
2023-03-21 20:39:30.067063: predicting hippocampus_039 
2023-03-21 20:39:30.236393: predicting hippocampus_051 
2023-03-21 20:39:30.339596: predicting hippocampus_058 
2023-03-21 20:39:30.476396: predicting hippocampus_060 
2023-03-21 20:39:30.616997: predicting hippocampus_067 
2023-03-21 20:39:30.744672: predicting hippocampus_075 
2023-03-21 20:39:30.936953: predicting hippocampus_077 
2023-03-21 20:39:31.107942: predicting hippocampus_096 
2023-03-21 20:39:31.155052: predicting hippocampus_101 
2023-03-21 20:39:31.201949: predicting hippocampus_102 
2023-03-21 20:39:31.249487: predicting hippocampus_105 
2023-03-21 20:39:31.298359: predicting hippocampus_109 
2023-03-21 20:39:33.346894: predicting hippocampus_126 
2023-03-21 20:39:33.446478: predicting hippocampus_130 
2023-03-21 20:39:33.492608: predicting hippocampus_136 
2023-03-21 20:39:33.578649: predicting hippocampus_141 
2023-03-21 20:39:33.666016: predicting hippocampus_142 
2023-03-21 20:39:33.751010: predicting hippocampus_148 
2023-03-21 20:39:33.798218: predicting hippocampus_184 
2023-03-21 20:39:33.844745: predicting hippocampus_193 
2023-03-21 20:39:33.893822: predicting hippocampus_195 
2023-03-21 20:39:33.942647: predicting hippocampus_230 
2023-03-21 20:39:33.990047: predicting hippocampus_233 
2023-03-21 20:39:34.036284: predicting hippocampus_242 
2023-03-21 20:39:34.081186: predicting hippocampus_243 
2023-03-21 20:39:34.125242: predicting hippocampus_248 
2023-03-21 20:39:34.171401: predicting hippocampus_249 
2023-03-21 20:39:34.217389: predicting hippocampus_253 
2023-03-21 20:39:34.263010: predicting hippocampus_268 
2023-03-21 20:39:34.308732: predicting hippocampus_269 
2023-03-21 20:39:34.354802: predicting hippocampus_282 
2023-03-21 20:39:34.400544: predicting hippocampus_294 
2023-03-21 20:39:34.482579: predicting hippocampus_301 
2023-03-21 20:39:34.526695: predicting hippocampus_303 
2023-03-21 20:39:34.581321: predicting hippocampus_310 
2023-03-21 20:39:34.642371: predicting hippocampus_318 
2023-03-21 20:39:34.703904: predicting hippocampus_319 
2023-03-21 20:39:34.769726: predicting hippocampus_331 
2023-03-21 20:39:34.832448: predicting hippocampus_333 
2023-03-21 20:39:34.893726: predicting hippocampus_335 
2023-03-21 20:39:35.012438: predicting hippocampus_341 
2023-03-21 20:39:35.074261: predicting hippocampus_359 
2023-03-21 20:39:35.137139: predicting hippocampus_361 
2023-03-21 20:39:35.199471: predicting hippocampus_363 
2023-03-21 20:39:35.261135: predicting hippocampus_376 
2023-03-21 20:39:35.322738: predicting hippocampus_380 
2023-03-21 20:39:35.437706: predicting hippocampus_386 
2023-03-21 20:39:39.142132: Validation complete 
2023-03-21 20:39:39.142300: Mean Validation Dice:  0.8885751563315296 
