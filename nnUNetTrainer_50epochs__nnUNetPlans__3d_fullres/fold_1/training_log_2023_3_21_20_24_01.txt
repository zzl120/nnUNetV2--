
This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'num_pool_per_axis': [3, 3, 3], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2023-03-21 20:24:05.794719: unpacking dataset... 
2023-03-21 20:24:09.287475: unpacking done... 
2023-03-21 20:24:09.289634: do_dummy_2d_data_aug: False 
2023-03-21 20:24:09.294276: Using splits from existing split file: /data_hdd/users/zengzhilin/nnUNet_preprocessed/Dataset004_Hippocampus/splits_final.json 
2023-03-21 20:24:09.295183: The split file contains 5 splits. 
2023-03-21 20:24:09.295337: Desired fold for training: 1 
2023-03-21 20:24:09.295464: This split has 208 training and 52 validation cases. 
2023-03-21 20:24:09.353210: Unable to plot network architecture: 
2023-03-21 20:24:09.353480: No module named 'hiddenlayer' 
2023-03-21 20:24:09.409050:  
2023-03-21 20:24:09.409295: Epoch 0 
2023-03-21 20:24:09.409708: Current learning rate: 0.01 
2023-03-21 20:24:29.132469: train_loss -0.3274 
2023-03-21 20:24:29.132775: val_loss -0.752 
2023-03-21 20:24:29.132905: Pseudo dice [0.824, 0.8149] 
2023-03-21 20:24:29.133039: Epoch time: 19.73 s 
2023-03-21 20:24:29.133137: Yayy! New best EMA pseudo Dice: 0.8195 
2023-03-21 20:24:30.736146:  
2023-03-21 20:24:30.736528: Epoch 1 
2023-03-21 20:24:30.736865: Current learning rate: 0.00982 
2023-03-21 20:24:46.420326: train_loss -0.7582 
2023-03-21 20:24:46.420677: val_loss -0.8017 
2023-03-21 20:24:46.420825: Pseudo dice [0.8586, 0.8472] 
2023-03-21 20:24:46.420941: Epoch time: 15.69 s 
2023-03-21 20:24:46.421039: Yayy! New best EMA pseudo Dice: 0.8228 
2023-03-21 20:24:48.754518:  
2023-03-21 20:24:48.754704: Epoch 2 
2023-03-21 20:24:48.754869: Current learning rate: 0.00964 
2023-03-21 20:25:04.510324: train_loss -0.7958 
2023-03-21 20:25:04.510654: val_loss -0.8076 
2023-03-21 20:25:04.510794: Pseudo dice [0.8674, 0.8474] 
2023-03-21 20:25:04.510928: Epoch time: 15.76 s 
2023-03-21 20:25:04.511034: Yayy! New best EMA pseudo Dice: 0.8263 
2023-03-21 20:25:06.635924:  
2023-03-21 20:25:06.636088: Epoch 3 
2023-03-21 20:25:06.636216: Current learning rate: 0.00946 
2023-03-21 20:25:22.192500: train_loss -0.8094 
2023-03-21 20:25:22.192789: val_loss -0.821 
2023-03-21 20:25:22.192925: Pseudo dice [0.8741, 0.8597] 
2023-03-21 20:25:22.193039: Epoch time: 15.56 s 
2023-03-21 20:25:22.193145: Yayy! New best EMA pseudo Dice: 0.8303 
2023-03-21 20:25:24.000249:  
2023-03-21 20:25:24.000463: Epoch 4 
2023-03-21 20:25:24.000600: Current learning rate: 0.00928 
2023-03-21 20:25:39.391589: train_loss -0.8181 
2023-03-21 20:25:39.391884: val_loss -0.8226 
2023-03-21 20:25:39.392031: Pseudo dice [0.8747, 0.8625] 
2023-03-21 20:25:39.392153: Epoch time: 15.39 s 
2023-03-21 20:25:39.392254: Yayy! New best EMA pseudo Dice: 0.8341 
2023-03-21 20:25:41.323353:  
2023-03-21 20:25:41.323632: Epoch 5 
2023-03-21 20:25:41.323761: Current learning rate: 0.0091 
2023-03-21 20:25:56.647264: train_loss -0.824 
2023-03-21 20:25:56.647551: val_loss -0.8261 
2023-03-21 20:25:56.647674: Pseudo dice [0.8778, 0.8628] 
2023-03-21 20:25:56.647790: Epoch time: 15.32 s 
2023-03-21 20:25:56.647889: Yayy! New best EMA pseudo Dice: 0.8378 
2023-03-21 20:25:58.464061:  
2023-03-21 20:25:58.464243: Epoch 6 
2023-03-21 20:25:58.464459: Current learning rate: 0.00891 
2023-03-21 20:26:13.719471: train_loss -0.83 
2023-03-21 20:26:13.719766: val_loss -0.8332 
2023-03-21 20:26:13.720402: Pseudo dice [0.8835, 0.8671] 
2023-03-21 20:26:13.720546: Epoch time: 15.26 s 
2023-03-21 20:26:13.720649: Yayy! New best EMA pseudo Dice: 0.8415 
2023-03-21 20:26:15.453891:  
2023-03-21 20:26:15.454062: Epoch 7 
2023-03-21 20:26:15.454273: Current learning rate: 0.00873 
2023-03-21 20:26:31.129477: train_loss -0.8331 
2023-03-21 20:26:31.130003: val_loss -0.8325 
2023-03-21 20:26:31.130173: Pseudo dice [0.8851, 0.8666] 
2023-03-21 20:26:31.130312: Epoch time: 15.68 s 
2023-03-21 20:26:31.130531: Yayy! New best EMA pseudo Dice: 0.845 
2023-03-21 20:26:33.188462:  
2023-03-21 20:26:33.188658: Epoch 8 
2023-03-21 20:26:33.188808: Current learning rate: 0.00855 
2023-03-21 20:26:48.833638: train_loss -0.8344 
2023-03-21 20:26:48.834444: val_loss -0.8332 
2023-03-21 20:26:48.834977: Pseudo dice [0.8826, 0.8661] 
2023-03-21 20:26:48.835155: Epoch time: 15.65 s 
2023-03-21 20:26:48.835475: Yayy! New best EMA pseudo Dice: 0.8479 
2023-03-21 20:26:50.819426:  
2023-03-21 20:26:50.819668: Epoch 9 
2023-03-21 20:26:50.819815: Current learning rate: 0.00836 
2023-03-21 20:27:06.521840: train_loss -0.8396 
2023-03-21 20:27:06.522152: val_loss -0.8333 
2023-03-21 20:27:06.522286: Pseudo dice [0.8847, 0.8657] 
2023-03-21 20:27:06.522426: Epoch time: 15.7 s 
2023-03-21 20:27:06.522533: Yayy! New best EMA pseudo Dice: 0.8506 
2023-03-21 20:27:08.399918:  
2023-03-21 20:27:08.400088: Epoch 10 
2023-03-21 20:27:08.400225: Current learning rate: 0.00818 
2023-03-21 20:27:24.058674: train_loss -0.8406 
2023-03-21 20:27:24.059448: val_loss -0.8369 
2023-03-21 20:27:24.059602: Pseudo dice [0.8889, 0.8675] 
2023-03-21 20:27:24.059746: Epoch time: 15.66 s 
2023-03-21 20:27:24.059856: Yayy! New best EMA pseudo Dice: 0.8534 
2023-03-21 20:27:25.996963:  
2023-03-21 20:27:25.997222: Epoch 11 
2023-03-21 20:27:25.997361: Current learning rate: 0.008 
2023-03-21 20:27:41.489748: train_loss -0.8429 
2023-03-21 20:27:41.490072: val_loss -0.8395 
2023-03-21 20:27:41.490195: Pseudo dice [0.8878, 0.872] 
2023-03-21 20:27:41.490312: Epoch time: 15.49 s 
2023-03-21 20:27:41.490410: Yayy! New best EMA pseudo Dice: 0.856 
2023-03-21 20:27:43.508718:  
2023-03-21 20:27:43.509595: Epoch 12 
2023-03-21 20:27:43.509987: Current learning rate: 0.00781 
2023-03-21 20:27:59.533669: train_loss -0.8465 
2023-03-21 20:27:59.534076: val_loss -0.8429 
2023-03-21 20:27:59.534216: Pseudo dice [0.8923, 0.8735] 
2023-03-21 20:27:59.534343: Epoch time: 16.03 s 
2023-03-21 20:27:59.534449: Yayy! New best EMA pseudo Dice: 0.8587 
2023-03-21 20:28:01.619157:  
2023-03-21 20:28:01.619925: Epoch 13 
2023-03-21 20:28:01.620330: Current learning rate: 0.00763 
2023-03-21 20:28:17.569295: train_loss -0.8485 
2023-03-21 20:28:17.569666: val_loss -0.8385 
2023-03-21 20:28:17.569799: Pseudo dice [0.8862, 0.8709] 
2023-03-21 20:28:17.569923: Epoch time: 15.95 s 
2023-03-21 20:28:17.570025: Yayy! New best EMA pseudo Dice: 0.8607 
2023-03-21 20:28:19.514920:  
2023-03-21 20:28:19.515295: Epoch 14 
2023-03-21 20:28:19.515449: Current learning rate: 0.00744 
2023-03-21 20:28:35.686442: train_loss -0.8501 
2023-03-21 20:28:35.686862: val_loss -0.8372 
2023-03-21 20:28:35.687024: Pseudo dice [0.8884, 0.8682] 
2023-03-21 20:28:35.687141: Epoch time: 16.17 s 
2023-03-21 20:28:35.687234: Yayy! New best EMA pseudo Dice: 0.8625 
2023-03-21 20:28:37.663072:  
2023-03-21 20:28:37.663267: Epoch 15 
2023-03-21 20:28:37.663421: Current learning rate: 0.00725 
2023-03-21 20:28:53.606052: train_loss -0.8499 
2023-03-21 20:28:53.606842: val_loss -0.8391 
2023-03-21 20:28:53.606989: Pseudo dice [0.8881, 0.8701] 
2023-03-21 20:28:53.607157: Epoch time: 15.94 s 
2023-03-21 20:28:53.607276: Yayy! New best EMA pseudo Dice: 0.8641 
2023-03-21 20:28:55.448438:  
2023-03-21 20:28:55.448613: Epoch 16 
2023-03-21 20:28:55.448798: Current learning rate: 0.00707 
2023-03-21 20:29:11.515249: train_loss -0.8519 
2023-03-21 20:29:11.515959: val_loss -0.8441 
2023-03-21 20:29:11.516194: Pseudo dice [0.8944, 0.8732] 
2023-03-21 20:29:11.516412: Epoch time: 16.07 s 
2023-03-21 20:29:11.516591: Yayy! New best EMA pseudo Dice: 0.8661 
2023-03-21 20:29:13.483148:  
2023-03-21 20:29:13.483450: Epoch 17 
2023-03-21 20:29:13.483705: Current learning rate: 0.00688 
2023-03-21 20:29:29.541444: train_loss -0.8512 
2023-03-21 20:29:29.541949: val_loss -0.8456 
2023-03-21 20:29:29.542189: Pseudo dice [0.8939, 0.8748] 
2023-03-21 20:29:29.542474: Epoch time: 16.06 s 
2023-03-21 20:29:29.542629: Yayy! New best EMA pseudo Dice: 0.8679 
2023-03-21 20:29:31.855372:  
2023-03-21 20:29:31.855574: Epoch 18 
2023-03-21 20:29:31.855712: Current learning rate: 0.00669 
2023-03-21 20:29:47.479674: train_loss -0.8543 
2023-03-21 20:29:47.480020: val_loss -0.8422 
2023-03-21 20:29:47.480420: Pseudo dice [0.8905, 0.8719] 
2023-03-21 20:29:47.480546: Epoch time: 15.63 s 
2023-03-21 20:29:47.480652: Yayy! New best EMA pseudo Dice: 0.8692 
2023-03-21 20:29:49.289415:  
2023-03-21 20:29:49.289588: Epoch 19 
2023-03-21 20:29:49.289763: Current learning rate: 0.0065 
2023-03-21 20:30:05.033163: train_loss -0.8545 
2023-03-21 20:30:05.033660: val_loss -0.8461 
2023-03-21 20:30:05.034361: Pseudo dice [0.8931, 0.8769] 
2023-03-21 20:30:05.034473: Epoch time: 15.74 s 
2023-03-21 20:30:05.034570: Yayy! New best EMA pseudo Dice: 0.8708 
2023-03-21 20:30:06.985695:  
2023-03-21 20:30:06.985912: Epoch 20 
2023-03-21 20:30:06.986048: Current learning rate: 0.00631 
2023-03-21 20:30:22.759644: train_loss -0.8569 
2023-03-21 20:30:22.760426: val_loss -0.8405 
2023-03-21 20:30:22.760569: Pseudo dice [0.892, 0.8701] 
2023-03-21 20:30:22.760724: Epoch time: 15.77 s 
2023-03-21 20:30:22.760844: Yayy! New best EMA pseudo Dice: 0.8718 
2023-03-21 20:30:24.865196:  
2023-03-21 20:30:24.865372: Epoch 21 
2023-03-21 20:30:24.865515: Current learning rate: 0.00612 
2023-03-21 20:30:40.792126: train_loss -0.8578 
2023-03-21 20:30:40.792414: val_loss -0.8402 
2023-03-21 20:30:40.792544: Pseudo dice [0.8917, 0.8704] 
2023-03-21 20:30:40.792658: Epoch time: 15.93 s 
2023-03-21 20:30:40.792756: Yayy! New best EMA pseudo Dice: 0.8728 
2023-03-21 20:30:42.506622:  
2023-03-21 20:30:42.506850: Epoch 22 
2023-03-21 20:30:42.507032: Current learning rate: 0.00593 
2023-03-21 20:30:58.391392: train_loss -0.8568 
2023-03-21 20:30:58.392086: val_loss -0.8412 
2023-03-21 20:30:58.392226: Pseudo dice [0.8934, 0.8698] 
2023-03-21 20:30:58.392363: Epoch time: 15.89 s 
2023-03-21 20:30:58.392480: Yayy! New best EMA pseudo Dice: 0.8737 
2023-03-21 20:31:00.478098:  
2023-03-21 20:31:00.478393: Epoch 23 
2023-03-21 20:31:00.478598: Current learning rate: 0.00574 
2023-03-21 20:31:16.024328: train_loss -0.8582 
2023-03-21 20:31:16.024625: val_loss -0.8502 
2023-03-21 20:31:16.024747: Pseudo dice [0.8967, 0.88] 
2023-03-21 20:31:16.024863: Epoch time: 15.55 s 
2023-03-21 20:31:16.024971: Yayy! New best EMA pseudo Dice: 0.8751 
2023-03-21 20:31:17.700745:  
2023-03-21 20:31:17.700914: Epoch 24 
2023-03-21 20:31:17.701048: Current learning rate: 0.00555 
2023-03-21 20:31:33.442582: train_loss -0.8617 
2023-03-21 20:31:33.442907: val_loss -0.8444 
2023-03-21 20:31:33.443050: Pseudo dice [0.8929, 0.8741] 
2023-03-21 20:31:33.443168: Epoch time: 15.74 s 
2023-03-21 20:31:33.443287: Yayy! New best EMA pseudo Dice: 0.876 
2023-03-21 20:31:35.233161:  
2023-03-21 20:31:35.233331: Epoch 25 
2023-03-21 20:31:35.233466: Current learning rate: 0.00536 
2023-03-21 20:31:50.725736: train_loss -0.8631 
2023-03-21 20:31:50.726037: val_loss -0.8431 
2023-03-21 20:31:50.726161: Pseudo dice [0.8909, 0.8734] 
2023-03-21 20:31:50.726280: Epoch time: 15.49 s 
2023-03-21 20:31:50.726378: Yayy! New best EMA pseudo Dice: 0.8766 
2023-03-21 20:31:52.469127:  
2023-03-21 20:31:52.469291: Epoch 26 
2023-03-21 20:31:52.469456: Current learning rate: 0.00517 
2023-03-21 20:32:08.133917: train_loss -0.8643 
2023-03-21 20:32:08.134234: val_loss -0.8428 
2023-03-21 20:32:08.134362: Pseudo dice [0.8896, 0.8758] 
2023-03-21 20:32:08.134481: Epoch time: 15.67 s 
2023-03-21 20:32:08.134583: Yayy! New best EMA pseudo Dice: 0.8772 
2023-03-21 20:32:10.001374:  
2023-03-21 20:32:10.001604: Epoch 27 
2023-03-21 20:32:10.001743: Current learning rate: 0.00497 
2023-03-21 20:32:25.529187: train_loss -0.8644 
2023-03-21 20:32:25.529604: val_loss -0.8495 
2023-03-21 20:32:25.529934: Pseudo dice [0.8954, 0.8802] 
2023-03-21 20:32:25.530205: Epoch time: 15.53 s 
2023-03-21 20:32:25.530382: Yayy! New best EMA pseudo Dice: 0.8782 
2023-03-21 20:32:27.590686:  
2023-03-21 20:32:27.590877: Epoch 28 
2023-03-21 20:32:27.591031: Current learning rate: 0.00478 
2023-03-21 20:32:43.156053: train_loss -0.8641 
2023-03-21 20:32:43.156487: val_loss -0.8459 
2023-03-21 20:32:43.156619: Pseudo dice [0.8941, 0.8754] 
2023-03-21 20:32:43.156741: Epoch time: 15.57 s 
2023-03-21 20:32:43.156881: Yayy! New best EMA pseudo Dice: 0.8789 
2023-03-21 20:32:44.898619:  
2023-03-21 20:32:44.898812: Epoch 29 
2023-03-21 20:32:44.898945: Current learning rate: 0.00458 
2023-03-21 20:33:00.552909: train_loss -0.8658 
2023-03-21 20:33:00.553223: val_loss -0.8473 
2023-03-21 20:33:00.553353: Pseudo dice [0.8943, 0.8783] 
2023-03-21 20:33:00.553483: Epoch time: 15.66 s 
2023-03-21 20:33:00.553586: Yayy! New best EMA pseudo Dice: 0.8796 
2023-03-21 20:33:02.411831:  
2023-03-21 20:33:02.412008: Epoch 30 
2023-03-21 20:33:02.412146: Current learning rate: 0.00438 
2023-03-21 20:33:17.956034: train_loss -0.8665 
2023-03-21 20:33:17.956313: val_loss -0.8484 
2023-03-21 20:33:17.956439: Pseudo dice [0.8948, 0.8783] 
2023-03-21 20:33:17.956560: Epoch time: 15.55 s 
2023-03-21 20:33:17.956663: Yayy! New best EMA pseudo Dice: 0.8803 
2023-03-21 20:33:19.801814:  
2023-03-21 20:33:19.802045: Epoch 31 
2023-03-21 20:33:19.802207: Current learning rate: 0.00419 
2023-03-21 20:33:35.122933: train_loss -0.8667 
2023-03-21 20:33:35.123339: val_loss -0.8441 
2023-03-21 20:33:35.123517: Pseudo dice [0.8924, 0.8741] 
2023-03-21 20:33:35.123682: Epoch time: 15.32 s 
2023-03-21 20:33:35.123821: Yayy! New best EMA pseudo Dice: 0.8806 
2023-03-21 20:33:37.070605:  
2023-03-21 20:33:37.070800: Epoch 32 
2023-03-21 20:33:37.070935: Current learning rate: 0.00399 
2023-03-21 20:33:52.864070: train_loss -0.8694 
2023-03-21 20:33:52.864335: val_loss -0.8436 
2023-03-21 20:33:52.864455: Pseudo dice [0.892, 0.8733] 
2023-03-21 20:33:52.864610: Epoch time: 15.79 s 
2023-03-21 20:33:52.864763: Yayy! New best EMA pseudo Dice: 0.8808 
2023-03-21 20:33:54.657138:  
2023-03-21 20:33:54.657471: Epoch 33 
2023-03-21 20:33:54.657738: Current learning rate: 0.00379 
2023-03-21 20:34:10.063564: train_loss -0.8675 
2023-03-21 20:34:10.063868: val_loss -0.8483 
2023-03-21 20:34:10.063992: Pseudo dice [0.8947, 0.8777] 
2023-03-21 20:34:10.064109: Epoch time: 15.41 s 
2023-03-21 20:34:10.064209: Yayy! New best EMA pseudo Dice: 0.8814 
2023-03-21 20:34:12.016686:  
2023-03-21 20:34:12.016868: Epoch 34 
2023-03-21 20:34:12.017001: Current learning rate: 0.00359 
2023-03-21 20:34:28.026432: train_loss -0.8696 
2023-03-21 20:34:28.026762: val_loss -0.8482 
2023-03-21 20:34:28.026908: Pseudo dice [0.8957, 0.8777] 
2023-03-21 20:34:28.027039: Epoch time: 16.01 s 
2023-03-21 20:34:28.027150: Yayy! New best EMA pseudo Dice: 0.8819 
2023-03-21 20:34:29.961217:  
2023-03-21 20:34:29.961438: Epoch 35 
2023-03-21 20:34:29.961681: Current learning rate: 0.00338 
2023-03-21 20:34:45.679785: train_loss -0.8707 
2023-03-21 20:34:45.680084: val_loss -0.8474 
2023-03-21 20:34:45.680222: Pseudo dice [0.8963, 0.8752] 
2023-03-21 20:34:45.680357: Epoch time: 15.72 s 
2023-03-21 20:34:45.680462: Yayy! New best EMA pseudo Dice: 0.8823 
2023-03-21 20:34:47.613249:  
2023-03-21 20:34:47.613418: Epoch 36 
2023-03-21 20:34:47.613567: Current learning rate: 0.00318 
2023-03-21 20:35:02.807457: train_loss -0.8713 
2023-03-21 20:35:02.807757: val_loss -0.8494 
2023-03-21 20:35:02.807896: Pseudo dice [0.8964, 0.8801] 
2023-03-21 20:35:02.808022: Epoch time: 15.19 s 
2023-03-21 20:35:02.808125: Yayy! New best EMA pseudo Dice: 0.8829 
2023-03-21 20:35:04.868903:  
2023-03-21 20:35:04.869127: Epoch 37 
2023-03-21 20:35:04.869272: Current learning rate: 0.00297 
2023-03-21 20:35:20.386687: train_loss -0.8731 
2023-03-21 20:35:20.387040: val_loss -0.8452 
2023-03-21 20:35:20.387169: Pseudo dice [0.8935, 0.8742] 
2023-03-21 20:35:20.387297: Epoch time: 15.52 s 
2023-03-21 20:35:20.387400: Yayy! New best EMA pseudo Dice: 0.883 
2023-03-21 20:35:22.292664:  
2023-03-21 20:35:22.292833: Epoch 38 
2023-03-21 20:35:22.293015: Current learning rate: 0.00277 
2023-03-21 20:35:37.708767: train_loss -0.8724 
2023-03-21 20:35:37.709100: val_loss -0.8485 
2023-03-21 20:35:37.709225: Pseudo dice [0.8959, 0.8771] 
2023-03-21 20:35:37.709357: Epoch time: 15.42 s 
2023-03-21 20:35:37.709466: Yayy! New best EMA pseudo Dice: 0.8833 
2023-03-21 20:35:39.650954:  
2023-03-21 20:35:39.651124: Epoch 39 
2023-03-21 20:35:39.651284: Current learning rate: 0.00256 
2023-03-21 20:35:55.430630: train_loss -0.8718 
2023-03-21 20:35:55.431089: val_loss -0.8422 
2023-03-21 20:35:55.431392: Pseudo dice [0.8916, 0.8734] 
2023-03-21 20:35:55.431692: Epoch time: 15.78 s 
2023-03-21 20:35:57.044717:  
2023-03-21 20:35:57.044892: Epoch 40 
2023-03-21 20:35:57.045026: Current learning rate: 0.00235 
2023-03-21 20:36:12.446800: train_loss -0.8743 
2023-03-21 20:36:12.447284: val_loss -0.8455 
2023-03-21 20:36:12.447543: Pseudo dice [0.8928, 0.875] 
2023-03-21 20:36:12.447975: Epoch time: 15.4 s 
2023-03-21 20:36:14.092316:  
2023-03-21 20:36:14.092560: Epoch 41 
2023-03-21 20:36:14.092697: Current learning rate: 0.00214 
2023-03-21 20:36:29.565434: train_loss -0.8743 
2023-03-21 20:36:29.565923: val_loss -0.8446 
2023-03-21 20:36:29.566146: Pseudo dice [0.8939, 0.8728] 
2023-03-21 20:36:29.566360: Epoch time: 15.47 s 
2023-03-21 20:36:31.332043:  
2023-03-21 20:36:31.332300: Epoch 42 
2023-03-21 20:36:31.332534: Current learning rate: 0.00192 
2023-03-21 20:36:46.981553: train_loss -0.8767 
2023-03-21 20:36:46.981881: val_loss -0.8414 
2023-03-21 20:36:46.982021: Pseudo dice [0.8906, 0.8727] 
2023-03-21 20:36:46.982154: Epoch time: 15.65 s 
2023-03-21 20:36:48.529483:  
2023-03-21 20:36:48.529669: Epoch 43 
2023-03-21 20:36:48.529804: Current learning rate: 0.0017 
2023-03-21 20:37:03.957928: train_loss -0.8757 
2023-03-21 20:37:03.958210: val_loss -0.843 
2023-03-21 20:37:03.958337: Pseudo dice [0.8926, 0.8748] 
2023-03-21 20:37:03.958453: Epoch time: 15.43 s 
2023-03-21 20:37:05.426476:  
2023-03-21 20:37:05.426639: Epoch 44 
2023-03-21 20:37:05.426783: Current learning rate: 0.00148 
2023-03-21 20:37:21.389525: train_loss -0.876 
2023-03-21 20:37:21.389817: val_loss -0.8476 
2023-03-21 20:37:21.389945: Pseudo dice [0.8965, 0.8766] 
2023-03-21 20:37:21.390084: Epoch time: 15.96 s 
2023-03-21 20:37:21.390191: Yayy! New best EMA pseudo Dice: 0.8835 
2023-03-21 20:37:23.164150:  
2023-03-21 20:37:23.164341: Epoch 45 
2023-03-21 20:37:23.164467: Current learning rate: 0.00126 
2023-03-21 20:37:38.699459: train_loss -0.879 
2023-03-21 20:37:38.699758: val_loss -0.8499 
2023-03-21 20:37:38.699881: Pseudo dice [0.8975, 0.8775] 
2023-03-21 20:37:38.700001: Epoch time: 15.54 s 
2023-03-21 20:37:38.700107: Yayy! New best EMA pseudo Dice: 0.8839 
2023-03-21 20:37:40.591284:  
2023-03-21 20:37:40.591645: Epoch 46 
2023-03-21 20:37:40.591873: Current learning rate: 0.00103 
2023-03-21 20:37:56.473910: train_loss -0.8791 
2023-03-21 20:37:56.474492: val_loss -0.8464 
2023-03-21 20:37:56.475070: Pseudo dice [0.8948, 0.8756] 
2023-03-21 20:37:56.475329: Epoch time: 15.88 s 
2023-03-21 20:37:56.475570: Yayy! New best EMA pseudo Dice: 0.8841 
2023-03-21 20:37:58.318243:  
2023-03-21 20:37:58.319064: Epoch 47 
2023-03-21 20:37:58.319611: Current learning rate: 0.00079 
2023-03-21 20:38:14.294918: train_loss -0.8804 
2023-03-21 20:38:14.295860: val_loss -0.8436 
2023-03-21 20:38:14.296079: Pseudo dice [0.8918, 0.8746] 
2023-03-21 20:38:14.296266: Epoch time: 15.98 s 
2023-03-21 20:38:16.058548:  
2023-03-21 20:38:16.058744: Epoch 48 
2023-03-21 20:38:16.058905: Current learning rate: 0.00055 
2023-03-21 20:38:31.972532: train_loss -0.8789 
2023-03-21 20:38:31.973437: val_loss -0.8428 
2023-03-21 20:38:31.973698: Pseudo dice [0.8916, 0.8741] 
2023-03-21 20:38:31.973949: Epoch time: 15.91 s 
2023-03-21 20:38:33.528082:  
2023-03-21 20:38:33.528399: Epoch 49 
2023-03-21 20:38:33.528674: Current learning rate: 0.0003 
2023-03-21 20:38:50.046037: train_loss -0.8791 
2023-03-21 20:38:50.046703: val_loss -0.8398 
2023-03-21 20:38:50.047120: Pseudo dice [0.8898, 0.8711] 
2023-03-21 20:38:50.047760: Epoch time: 16.52 s 
2023-03-21 20:38:52.400185: Using splits from existing split file: /data_hdd/users/zengzhilin/nnUNet_preprocessed/Dataset004_Hippocampus/splits_final.json 
2023-03-21 20:38:52.401424: The split file contains 5 splits. 
2023-03-21 20:38:52.401510: Desired fold for training: 1 
2023-03-21 20:38:52.401589: This split has 208 training and 52 validation cases. 
2023-03-21 20:38:52.402309: predicting hippocampus_003 
2023-03-21 20:38:52.607396: predicting hippocampus_025 
2023-03-21 20:38:52.722774: predicting hippocampus_026 
2023-03-21 20:38:52.885253: predicting hippocampus_034 
2023-03-21 20:38:53.004434: predicting hippocampus_036 
2023-03-21 20:38:53.066591: predicting hippocampus_044 
2023-03-21 20:38:53.156085: predicting hippocampus_045 
2023-03-21 20:38:53.325104: predicting hippocampus_064 
2023-03-21 20:38:53.419238: predicting hippocampus_087 
2023-03-21 20:38:53.509321: predicting hippocampus_093 
2023-03-21 20:38:53.649510: predicting hippocampus_094 
2023-03-21 20:38:53.705695: predicting hippocampus_106 
2023-03-21 20:38:53.759382: predicting hippocampus_114 
2023-03-21 20:38:53.858753: predicting hippocampus_144 
2023-03-21 20:38:53.976490: predicting hippocampus_149 
2023-03-21 20:38:54.094303: predicting hippocampus_154 
2023-03-21 20:38:54.214637: predicting hippocampus_155 
2023-03-21 20:38:56.278180: predicting hippocampus_162 
2023-03-21 20:38:56.348480: predicting hippocampus_163 
2023-03-21 20:38:56.453460: predicting hippocampus_166 
2023-03-21 20:38:56.531667: predicting hippocampus_171 
2023-03-21 20:38:56.601879: predicting hippocampus_177 
2023-03-21 20:38:56.670017: predicting hippocampus_203 
2023-03-21 20:38:56.732361: predicting hippocampus_215 
2023-03-21 20:38:56.792409: predicting hippocampus_223 
2023-03-21 20:38:56.854458: predicting hippocampus_228 
2023-03-21 20:38:56.912169: predicting hippocampus_231 
2023-03-21 20:38:57.059337: predicting hippocampus_234 
2023-03-21 20:38:57.143113: predicting hippocampus_235 
2023-03-21 20:38:57.265311: predicting hippocampus_236 
2023-03-21 20:38:57.378013: predicting hippocampus_238 
2023-03-21 20:38:57.434897: predicting hippocampus_245 
2023-03-21 20:38:57.538328: predicting hippocampus_250 
2023-03-21 20:38:57.597606: predicting hippocampus_263 
2023-03-21 20:38:57.652833: predicting hippocampus_274 
2023-03-21 20:38:57.709673: predicting hippocampus_287 
2023-03-21 20:38:57.765795: predicting hippocampus_295 
2023-03-21 20:38:57.823821: predicting hippocampus_299 
2023-03-21 20:38:57.879766: predicting hippocampus_300 
2023-03-21 20:38:57.937387: predicting hippocampus_309 
2023-03-21 20:38:57.995365: predicting hippocampus_316 
2023-03-21 20:38:58.052434: predicting hippocampus_321 
2023-03-21 20:38:58.106800: predicting hippocampus_328 
2023-03-21 20:38:58.159912: predicting hippocampus_329 
2023-03-21 20:38:58.230897: predicting hippocampus_336 
2023-03-21 20:38:58.338087: predicting hippocampus_337 
2023-03-21 20:38:58.437948: predicting hippocampus_345 
2023-03-21 20:38:58.499054: predicting hippocampus_351 
2023-03-21 20:38:58.559150: predicting hippocampus_352 
2023-03-21 20:38:58.618322: predicting hippocampus_354 
2023-03-21 20:38:58.677324: predicting hippocampus_355 
2023-03-21 20:38:58.734404: predicting hippocampus_360 
2023-03-21 20:39:03.089331: Validation complete 
2023-03-21 20:39:03.089508: Mean Validation Dice:  0.8859856130286397 
